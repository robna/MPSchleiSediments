{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, LeavePOut\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import prepare_data\n",
    "from components import PCOA\n",
    "from helpers import PipelineHelper, SMWrapper\n",
    "from settings import Config, shortnames, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% loading data\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 samples with less than 0 particles.\n",
      "Series([], dtype: float64)\n",
      "PCoA: Proportion explained: \n",
      " PC1    0.796518\n",
      "PC2    0.105473\n",
      "dtype: float64    PCoA Total: 0.901991651784579\n",
      "PCoA: Proportion explained: \n",
      " PC1    0.676644\n",
      "PC2    0.153534\n",
      "dtype: float64    PCoA Total: 0.8301779851270285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/git/MPSchleiSediments/analysis/prepare_data.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  mp_pdd.columns = mp_pdd.columns.str.replace(\"[\\[( )\\]]\", \"\")  # remove brackets from column names\n",
      "/home/rob/.local/share/virtualenvs/MPSchleiSediments-z4CtktJ9/lib/python3.9/site-packages/skbio/stats/ordination/_principal_coordinate_analysis.py:143: RuntimeWarning: The result contains negative eigenvalues. Please compare their magnitude with the magnitude of some of the largest positive eigenvalues. If the negative ones are smaller, it's probably safe to ignore them, but if they are large in magnitude, the results won't be useful. See the Notes section for more details. The smallest eigenvalue is -0.042165027282667356 and the largest is 4.028697526088318.\n",
      "  warn(\n",
      "/home/rob/.local/share/virtualenvs/MPSchleiSediments-z4CtktJ9/lib/python3.9/site-packages/skbio/stats/ordination/_principal_coordinate_analysis.py:143: RuntimeWarning: The result contains negative eigenvalues. Please compare their magnitude with the magnitude of some of the largest positive eigenvalues. If the negative ones are smaller, it's probably safe to ignore them, but if they are large in magnitude, the results won't be useful. See the Notes section for more details. The smallest eigenvalue is -0.37546256583985693 and the largest is 23.051107802847195.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# What happened so far: DB extract and blank procedure. Now import resulting MP data from csv\n",
    "mp_pdd = prepare_data.get_pdd()\n",
    "\n",
    "# Also import sediment data (sediment frequencies per size bin from master sizer export)\n",
    "grainsize_iow, grainsize_cau = prepare_data.get_grainsizes()[0:2]\n",
    "scor_iow = PCOA(grainsize_iow, 2)[0]\n",
    "scor_cau = PCOA(grainsize_cau, 2)[0]\n",
    "\n",
    "# ...some data wrangling to prepare particle domain data and sample domain data for MP and combine with certain sediment aggregates.\n",
    "sdd_iow = prepare_data.aggregate_SDD(mp_pdd)\n",
    "sdd_iow = prepare_data.additional_sdd_merging(sdd_iow, how='outer')\n",
    "sdd_iow = sdd_iow.merge(scor_iow, right_index=True, left_on='Sample', how='outer')\n",
    "\n",
    "sdd_cau = pd.read_csv('../data/Metadata_CAU_sampling_log.csv', index_col=0).join(pd.read_csv('../data/GRADISTAT_CAU_vol_log-cau_closed.csv', index_col=0), how='outer')\n",
    "sdd_cau = sdd_cau.merge(scor_cau, right_index=True, left_on='Sample', how='outer').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdd_iow = sdd_iow.replace({'Sample': shortnames}).sort_values(by='Sample')\n",
    "model_data = sdd_iow.loc[~sdd_iow.Concentration.isna()].set_index('Sample')\n",
    "pred_data = sdd_iow.loc[sdd_iow.Concentration.isna()]\n",
    "pred_data = pd.concat([pred_data, sdd_cau.drop('Date',axis=1)]).set_index('Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist = [\n",
    "    'Depth',\n",
    "    'LON', 'LAT',\n",
    "    # 'Dist_Marina', 'Dist_WWTP', 'Dist_WWTP2',\n",
    "    'MODE 1 (µm)',\n",
    "    'D10 (µm)', 'D50 (µm)', 'D90 (µm)',\n",
    "    'perc GRAVEL', 'perc SAND', 'perc MUD', 'perc CLAY',\n",
    "    #'OM_D50', 'TOC', 'Hg', 'TIC', 'regio_sep',\n",
    "    'PC1', 'PC2'\n",
    "    ]\n",
    "model_X = model_data[featurelist]\n",
    "model_y = model_data[target]\n",
    "pred_X = pred_data[featurelist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', PipelineHelper([\n",
    "        ('std', StandardScaler()),\n",
    "        ('max', MaxAbsScaler()),\n",
    "        ('minmax', MinMaxScaler()),\n",
    "    ], optional=True)),\n",
    "\n",
    "    ('classifier', PipelineHelper([\n",
    "        # ('glm', SMWrapper(family=Config.glm_family, formula=Config.glm_formula)),\n",
    "        ('svm', SVR()),\n",
    "        ('rf', RandomForestRegressor()),\n",
    "        ('ada', AdaBoostRegressor()),\n",
    "        ('gb', GradientBoostingRegressor()),\n",
    "        ('knn', KNeighborsRegressor()),\n",
    "        ('rnn', RadiusNeighborsRegressor()),\n",
    "        ('nb_pipe', Pipeline([\n",
    "            # Naive Bayes needs positive numbers\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('nb', GaussianNB()),\n",
    "        ])),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'scaler__selected_model': pipe.named_steps['scaler'].generate(\n",
    "        {\n",
    "            'std__with_mean': [True, False],\n",
    "            'std__with_std': [True, False],\n",
    "            # no params for 'max' and 'minmax' leads to using standard params\n",
    "        }\n",
    "    ),\n",
    "    'classifier__selected_model': pipe.named_steps['classifier'].generate(\n",
    "        {\n",
    "            # 'glm__alpha': [0.0, 0.1, 0.2, 0.5, 1.0],\n",
    "            # 'glm__L1_wt': [0.1, 0.5, 1],\n",
    "            'svm__C': [0.1, 0.5, 1.0],\n",
    "            'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "            'svm__degree': [1, 2, 3, 4, 5],\n",
    "            'rf__n_estimators': [10, 20, 50, 100, 150],\n",
    "            'rf__max_features': ['sqrt', 'log2', None],\n",
    "            'rf__min_samples_split': [2, 5, 10],\n",
    "            'rf__min_samples_leaf': [1, 2, 4],\n",
    "            'rf__bootstrap': [True, False],\n",
    "            'rf__max_depth': [None, 2, 5, 10],\n",
    "            'rf__warm_start': [True, False],\n",
    "            'ada__n_estimators': [10, 20, 40, 100],\n",
    "            'ada__learning_rate': [0.1, 0.5, 1.0, 2.0],\n",
    "            'ada__loss': ['linear', 'square', 'exponential'],\n",
    "            'gb__n_estimators': [10, 20, 50, 100],\n",
    "            'gb__criterion': ['friedman_mse', 'squared_error'],\n",
    "            'gb__max_features': ['sqrt', None],\n",
    "            'knn__n_neighbors': [2, 3, 5, 7, 10],\n",
    "            'knn__leaf_size': [1, 2, 3, 5],\n",
    "            'knn__weights': ['uniform', 'distance'],\n",
    "            'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'rnn__radius': [0.1, 0.5, 1, 2, 5, 10],\n",
    "            'rnn__weights': ['uniform', 'distance'],\n",
    "            'rnn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'rnn__leaf_size': [1, 2, 3, 5],\n",
    "            # 'nb_pipe__nb__prior': None,\n",
    "        }\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 465 folds for each of 18354 candidates, totalling 8534610 fits\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(  # TODO: Possible to set random state for all estimators?\n",
    "    pipe,\n",
    "    params,\n",
    "    scoring='r2',  # possibilities: ‘neg_root_mean_squared_error’, ‘neg_mean_squared_error’, 'r2', 'neg_mean_absolute_error', 'neg_mean_squared_log_error'\n",
    "    cv=LeavePOut(2),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "grid.fit(model_X, model_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('MPSchleiSediments-z4CtktJ9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82a31816b63c673b7463547b8d8376fc489f1e362f1a21f244a13819d6095661"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
