{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DataTransformerRegistry.enable('default')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "try:  # if on phy-server local modules will not be found if their directory is not added to PATH\n",
    "    import sys\n",
    "    sys.path.append(\"/silod7/lenz/MPSchleiSediments/ProbDistFunc/\")\n",
    "    import os\n",
    "    os.chdir(\"/silod7/lenz/MPSchleiSediments/ProbDistFunc/\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import prepare_data\n",
    "import KDE_utils\n",
    "import correlations\n",
    "from pca import sed_pca\n",
    "from settings import Config\n",
    "from scipy import stats\n",
    "# alt.renderers.enable('altair_viewer')  # use to display altair charts externally in browser instead of inline (only activate in non-vega-compatible IDE like pycharm)\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MP particle size correlations\n",
    "\n",
    "*This calculates probability density distributions for MP sizes. These are used to estimate the abundances of MP of specific size ranges, which can then be investigated for correlations to environmental paramteres such as TOC or sediment grain size properties.*\n",
    "**Before running, check the computational parameters in KDE_settings.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% loading data\n"
    }
   },
   "outputs": [],
   "source": [
    "# What happened so far: DB extract and blank procedure. Now import resulting MP data from csv\n",
    "pdd_MP = pd.read_csv('../csv/env_MP_clean_list_SchleiSediments.csv', index_col=0)\n",
    "\n",
    "# Also import sediment data (sediment frequencies per size bin from master sizer export)\n",
    "sed_size_freqs = pd.read_csv('../csv/Enders_export_10Âµm_linear_noR_RL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the binning structure of the imported sediment data and optionally rebin it (make binning coarser) for faster computation\n",
    "sed_size_freqs, sed_x_d = prepare_data.sediment_preps(sed_size_freqs, rebinning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% data wrangling\n"
    }
   },
   "outputs": [],
   "source": [
    "# ...some data wrangling to prepare particle domain data and sample domain data for MP and combine with certain sediment aggregates.\n",
    "sdd_MP = prepare_data.aggregate_SDD(pdd_MP)\n",
    "sdd_MP_sed = prepare_data.add_sediment(sdd_MP)\n",
    "pdd_sdd_MP = prepare_data.sdd2pdd(sdd_MP_sed, pdd_MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% calculating probability densities\n"
    }
   },
   "outputs": [],
   "source": [
    "# KDEs for probability of finding a MP particle in a specific size bin are calculated.\n",
    "size_pdfs = KDE_utils.per_sample_kde(pdd_sdd_MP, x_d = sed_x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MP concentrations for each single-step size bin\n",
    "MP_size_conc = KDE_utils.probDens2conc(size_pdfs, sdd_MP_sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MP and sediment abundances per size bin are equalised (only samples and bins contained in both of the are kept).\n",
    "# They are then melted and merged into MPsedMelted.\n",
    "MP_size_conc, sed_size_freqs, MPsedMelted = prepare_data.equalise_MP_and_Sed(MP_size_conc, sed_size_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MP conc and sed freqs per size bin are calculated from the KDEs and the total MP concentration in the samples.\n",
    "#MP_size_conc_extended = KDE_utils.range_aggregator(MP_size_conc)\n",
    "#sed_size_freqs_extended = KDE_utils.range_aggregator(sed_size_freqs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sum abundances in size bins for all possible combinations. Basically create all possible rebinnings and stack them into one DF\n",
    "MPext = prepare_data.combination_sums(MP_size_conc.copy())\n",
    "SEDext= prepare_data.combination_sums(sed_size_freqs.copy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SEDpc, SEDexp, SEDload = sed_pca(SEDext.T)\n",
    "sedpc, sedexp, sedload = sed_pca(sed_size_freqs.T)\n",
    "\n",
    "# To see a loadings plot use:\n",
    "# sedload_df = pd.DataFrame(sedload, columns=['PC1', 'PC2', 'PC3'], index = np.unique(np.concatenate(np.char.split(sed_size_freqs.index.values.astype(str), '_')).ravel().astype(int))[:-1]).T\n",
    "# sedload_df.T.plot()  # x-axis corresponds to lower boundary of size bins"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Altair size range correlation (MP~Sed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MPsedExt = prepare_data.merge_size_ranges(MPext, 'MP', SEDext, 'SED', cart_prod=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "brush1 = alt.selection_interval(name=\"brush1\", encodings=['y'])\n",
    "brush2 = alt.selection_interval(name=\"brush2\", encodings=['x'])\n",
    "\n",
    "step = sed_x_d[1] - sed_x_d[0]\n",
    "\n",
    "scatter = alt.Chart(MPsedExt\n",
    ").transform_calculate(\n",
    "    b1l=f'floor((isDefined(brush1.y) ? (brush1.y[0][0]) : 1) / {step}) * {step}',\n",
    "    b1u=f'ceil((isDefined(brush1.y) ? (brush1.y[0][1]) : 1) / {step}) * {step}',\n",
    "    b2l=f'floor((isDefined(brush2.x) ? (brush2.x[0][0]) : 1) / {step}) * {step}',\n",
    "    b2u=f'ceil((isDefined(brush2.x) ? (brush2.x[0][1]) : 1) / {step}) * {step}',\n",
    ").mark_point().encode(\n",
    "    x = 'SED',\n",
    "    y = 'MP',\n",
    "    tooltip = 'sample:N'\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP >= datum.b1l) &&'\n",
    "    '(datum.upper_MP <= datum.b1u) &&'\n",
    "    '(datum.lower_SED >= datum.b2l) &&'\n",
    "    '(datum.upper_SED <= datum.b2u)'\n",
    ")\n",
    "    \n",
    "\n",
    "RegLine = scatter.transform_regression(\n",
    "    'SED', 'MP', method=\"linear\",\n",
    ").mark_line(\n",
    "    color=\"red\"\n",
    ")\n",
    "\n",
    "\n",
    "RegParams = scatter.transform_regression(\n",
    "    'SED', 'MP', method=\"linear\", params=True\n",
    ").mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(120),  # pixels from left\n",
    "    y=alt.value(20),  # pixels from top\n",
    "    text='params:N'\n",
    ").transform_calculate(\n",
    "    params='\"rÂ² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[1] * 100)/100 + \"x\" + \" + \" + round(datum.coef[0] * 10)/10'\n",
    ")\n",
    "\n",
    "\n",
    "MP = alt.Chart(MPsedExt).mark_line().encode(\n",
    "    x = 'mean(MP)',\n",
    "    y = alt.X('lower_MP', scale=alt.Scale(type='linear'))\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP == datum.lower_SED) && \\\n",
    "     (datum.upper_MP == datum.upper_SED)'\n",
    ").add_selection(\n",
    "    brush1\n",
    ").properties(\n",
    "    height = 300,\n",
    "    width = 100\n",
    ")\n",
    "\n",
    "\n",
    "sed = alt.Chart(MPsedExt).mark_line().encode(\n",
    "    x = alt.X('lower_SED', scale=alt.Scale(type='linear')),\n",
    "    y = 'mean(SED)'\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP == datum.lower_SED) &&'\n",
    "    '(datum.upper_MP == datum.upper_SED)'\n",
    ").add_selection(\n",
    "    brush2\n",
    ").properties(\n",
    "    height = 100,\n",
    "    width = 400\n",
    ")\n",
    "\n",
    "\n",
    "MP | (scatter + RegLine + RegParams) & sed\n",
    "\n",
    "# chart = MP | scatter & sed\n",
    "# chart#.save('chart.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size range correlation matrix (MP~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a correlation matrix containing Pearson correlation coefficients for all combinations of any original or summed bins of MP and sediments.\n",
    "corrMat = np.corrcoef(MPext,SEDext)\n",
    "corrMat = corrMat[:len(MPext), len(SEDext):]  # only take upper right quadrant of correlation matrix\n",
    "\n",
    "corrMatDF = pd.DataFrame(corrMat, index=MPext.index, columns=SEDext.index)  # turn np array into df\n",
    "# corrMatDF.rename('MP_{}'.format, axis=0, inplace=True)  # add a prefix for 'MP' to each row label\n",
    "# corrMatDF.rename('SED_{}'.format, axis=1, inplace=True)  # add a prefix for 'sediment' to each column label\n",
    "corrMatDF.index.name = 'MP'\n",
    "corrMatDF.columns.name = 'SED'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run a cross-correlation for each sample between MP and sediment size distribution curve shapes.\n",
    "crosscorr_results = pd.DataFrame()\n",
    "\n",
    "for label, content in df_range_conc.items():\n",
    "    datax = content\n",
    "    datay = sed_size_freqs[label]\n",
    "    #best = correlations.crosscorr(datax, datay)\n",
    "        \n",
    "#     lags = range(-int(len(datax)/2), int(len(datax)/2)+1)\n",
    "    lags = range(-50,0)\n",
    "    df_r = pd.DataFrame(lags, columns = ['shifted'])\n",
    "    \n",
    "#     r_pear = [datax.corr(datay.shift(lag)) for lag in lags]\n",
    "#     df_r['pearson_r'] = r_pear\n",
    "    r_spear = [stats.spearmanr(np.array(datax),np.array(datay.shift(lag)), nan_policy = 'omit') for lag in lags]\n",
    "    df_r['spearman_r'] = r_spear\n",
    "    \n",
    "    \n",
    "    best = df_r.copy().loc[df_r['spearman_r'] == df_r['spearman_r'].max()]\n",
    "    best['Sample'] = label\n",
    "    crosscorr_results = crosscorr_results.append(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MP-to-Scalar correlation (e.g. TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate correlation between all size bins (or their summed up combinations) of MP abundances and a scalar predictor.\n",
    "# Possible predictors are: 'TOC', 'Hg', 'Dist_WWTP' or different sediment grain size properties (D50, below 63, etc.). See column labels of sdd_MP_sed for a full list.\n",
    "bestLower, bestUpper, df_r = correlations.predictorcorr(df_range_conc, sdd_MP_sed.set_index('Sample'), 'TOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Heatmap correlation coefficients from the single predictor correlation\n",
    "alt.renderers.enable('html')\n",
    "\n",
    "alt.Chart(df_r).mark_point().encode(\n",
    "    x='lower_size',\n",
    "    y='upper_size',\n",
    "    color=alt.Color(\"r\", scale=alt.Scale(domain=[0.5, 0.6])),\n",
    "    tooltip=['r', 'lower_size', 'upper_size']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "#####USED only for testing external function inside NB: #####\n",
    "step = (Config.upper_size_limit - Config.lower_size_limit) / Config.kde_steps\n",
    "df_r = pd.DataFrame(columns=['lower_size', 'upper_size', 'r', 'p'])\n",
    "\n",
    "for i in [10]:\n",
    "    for j in [1000]:\n",
    "        size_sum = size_pdfs.loc[(size_pdfs.x_d >= i) & (size_pdfs.x_d < j)].sum()\n",
    "        size_sum.drop('x_d', inplace=True)\n",
    "        range_prob = size_sum * step\n",
    "        range_conc = range_prob * sdd_MP_sed.set_index('Sample').Concentration\n",
    "\n",
    "        r = stats.pearsonr(range_conc, sdd_MP_sed.set_index('Sample').TOC)\n",
    "        df_r.loc[len(df_r)] = [i, j, r[0], r[1]]\n",
    "        print(f'Correlating TOC with size range            [{i},        {j}]                ', end=\"\\r\", flush=True)\n",
    "\n",
    "print(df_r.loc[df_r.r == df_r.r.max()])\n",
    "bestLower, bestUpper = df_r.loc[df_r.r == df_r.r.max()].iloc[0, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Property-property-plot with MP against single predictor incl. reg line \n",
    "kd = alt.Chart(pd.DataFrame([range_conc, sdd_MP_sed.set_index('Sample').TOC]).T.reset_index()).mark_point().encode(\n",
    "    x='TOC',\n",
    "    y='Unnamed 0',\n",
    "    color='index',\n",
    "    tooltip='index'\n",
    ")\n",
    "\n",
    "Reg_Line = kd.transform_regression('TOC', 'Unnamed 0', method=\"linear\",\n",
    "                                  ).mark_line(color=\"red\")\n",
    "\n",
    "Reg_Params = kd.transform_regression('TOC', 'Unnamed 0', method=\"linear\", params=True\n",
    "                                    ).mark_text(align='left', lineBreak='\\n').encode(\n",
    "        x=alt.value(120),  # pixels from left\n",
    "        y=alt.value(20),  # pixels from top\n",
    "        text='params:N'\n",
    "    ).transform_calculate(\n",
    "        params='\"rÂ² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[0] * 10)/10 + \" + e ^ (\" + round(datum.coef[1] * 10000)/10000 + \"x\" + \")\" + \\n + \" \"'\n",
    "    )\n",
    "\n",
    "kd + Reg_Line + Reg_Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daf = sed_size_freqs.reset_index().melt(id_vars='index', value_name='value')\n",
    "daf['size'] = daf['index'].str.split('_').str[0]\n",
    "daf['category'] = 'sediment'\n",
    "\n",
    "daff = df_range_conc.reset_index().melt(id_vars='index', value_name='value')\n",
    "daff['size'] = daf['index'].str.split('_').str[0]\n",
    "daff['category'] = 'MP'\n",
    "\n",
    "df = pd.concat([daf, daff]).drop(columns=['index'])\n",
    "# df = daf.merge(daff, on =['sample', 'size', 'index']).drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dropdown = alt.binding_select(options=list(df['sample'].unique()), name='select sample ')\n",
    "selection = alt.selection_single(fields=['sample'],\n",
    "                                 bind=input_dropdown,\n",
    "                                 #init={'select_': 'Schlei_S8'}\n",
    "                                )\n",
    "\n",
    "base = alt.Chart(df).mark_line().encode(\n",
    "    x=alt.X('size:Q'),\n",
    "    y=alt.Y('value:Q'),\n",
    "    color='category',\n",
    "#     shape='category',\n",
    "#     detail='category'\n",
    "# ).transform_window(\n",
    "#     cuml='sum(value)',\n",
    "#     groupby=['sample']\n",
    ").transform_filter(\n",
    "    alt.FieldRangePredicate(field='size', range=[50, 990])\n",
    "# ).properties(\n",
    "#     width=180,\n",
    "#     height=180\n",
    "# ).facet(\n",
    "#     facet='sample',\n",
    "#     columns=6\n",
    "# ).resolve_scale(\n",
    "#     y='independent'\n",
    ")\n",
    "\n",
    "\n",
    "mps = base.mark_line(color='blue').transform_filter(\n",
    "    alt.FieldEqualPredicate(field='category', equal='MP')\n",
    ")\n",
    "seds = base.mark_line(color='yellow').transform_filter(\n",
    "    alt.FieldEqualPredicate(field='category', equal='sediment')\n",
    ")\n",
    "\n",
    "alt.layer(mps, seds).resolve_scale(\n",
    "    y = 'independent'\n",
    ").add_selection(\n",
    "    selection\n",
    ").transform_filter(\n",
    "    selection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = alt.Chart(df).encode(\n",
    "    alt.X('size:Q', axis=alt.Axis(title=None))\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ")\n",
    "\n",
    "mps = base.mark_line(stroke='#57A44C', interpolate='monotone').encode(\n",
    "    alt.Y('MP:Q', axis=alt.Axis(title='MP', titleColor='#57A44C'))\n",
    ")\n",
    "\n",
    "seds = base.mark_line(stroke='#5276A7', interpolate='monotone').encode(\n",
    "    alt.Y('sediment:Q', axis=alt.Axis(title='sediment', titleColor='#5276A7'))\n",
    ")\n",
    "\n",
    "alt.layer(mps, seds).resolve_scale(\n",
    "    y = 'independent'\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ").facet(\n",
    "    facet='sample',\n",
    "    columns=6\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = daf.shift(100).merge(daff, on =['sample', 'size', 'index']).drop(columns=['index'])\n",
    "alt.Chart(df).mark_point().encode(\n",
    "    x=alt.X('value_x', scale=alt.Scale(type='linear')),\n",
    "    y=alt.X('value_y', scale=alt.Scale(type='linear')),\n",
    "    color=alt.Color('size:Q', scale=alt.Scale(scheme=\"viridis\"))\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=150\n",
    ").facet(\n",
    "    facet='sample',\n",
    "    columns=6\n",
    ").resolve_scale(\n",
    "    y='independent',\n",
    "    x='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'x': range(9),\n",
    "    'y': [1, 2, 3, 4, 5, 4, 3, 2, 1]\n",
    "})\n",
    "\n",
    "brush = alt.selection_interval(name=\"brush\", encodings=['x'])\n",
    "alt.Chart(data).mark_line().add_selection(brush).transform_calculate(\n",
    "    scaled_by_brush_width='datum.y * (isDefined(brush.x) ? (brush.x[1] - brush.x[0]) : 1)'\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    y='scaled_by_brush_width:Q'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPSchleiSediments-bSFBF4Xj",
   "language": "python",
   "name": "mpschleisediments-bsfbf4xj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}