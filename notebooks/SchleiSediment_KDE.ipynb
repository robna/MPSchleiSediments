{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676bdbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "import altair_transform\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be04c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import quality checked and blank substracted list of MP from Micropoll_SchleiSediment_blank_subtract.ipynb\n",
    "env_MP = pd.read_csv('env_MP_clean_list_SchleiSediments.csv',index_col=0)\n",
    "#rename column name of Size_1\n",
    "env_MP.rename(columns = {'Size_1_[µm]':'Size_1_µm'}, inplace = True)\n",
    "#env_MP_a500 = env_MP.loc[env_MP.size_geom_mean >= 500]\n",
    "#env_MP_b500 = env_MP.loc[env_MP.size_geom_mean < 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2698e958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>FrequencyA500</th>\n",
       "      <th>FrequencyB500</th>\n",
       "      <th>Mass</th>\n",
       "      <th>GPS_LONs</th>\n",
       "      <th>GPS_LATs</th>\n",
       "      <th>Split</th>\n",
       "      <th>MP_D50</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>ConcentrationA500</th>\n",
       "      <th>ConcentrationB500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schlei_S10</td>\n",
       "      <td>297</td>\n",
       "      <td>4.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9.60355</td>\n",
       "      <td>54.5253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.732141</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1172.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample  Frequency  FrequencyA500  FrequencyB500  Mass  GPS_LONs  \\\n",
       "0  Schlei_S10        297            4.0          293.0  0.25   9.60355   \n",
       "\n",
       "   GPS_LATs  Split     MP_D50  Concentration  ConcentrationA500  \\\n",
       "0   54.5253    1.0  85.732141         1188.0               16.0   \n",
       "\n",
       "   ConcentrationB500  \n",
       "0             1172.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupy_env_MP = env_MP.groupby(['Sample'])\n",
    "\n",
    "mp_station = groupy_env_MP.agg(\n",
    "        Frequency=('Site_name', 'count'),  # using 'Site_name' here for count, could use any other column too... Is there a way to count entries in groups without using a column?\n",
    "        FrequencyA500=('size_geom_mean', lambda x: (x>=500).sum()),  # using 'Site_name' here for count, could use any other column too... Is there a way to count entries in groups without using a column?\n",
    "        FrequencyB500=('size_geom_mean', lambda x: (x<500).sum()),  # using 'Site_name' here for count, could use any other column too... Is there a way to count entries in groups without using a column?\n",
    "        Mass=('Sampling_weight_[kg]', np.mean),  # using \"mean\" here is actually weird as all entries are the same. Is there something like \"first\"?\n",
    "        GPS_LONs = ('GPS_LON', np.mean),\n",
    "        GPS_LATs = ('GPS_LAT', np.mean),\n",
    "        Split = ('Fraction_analysed', np.mean),\n",
    "        MP_D50 = ('size_geom_mean',np.median)\n",
    "        ##MP_D50_A500 = ('size_geom_mean' >= 500.median()),\n",
    "        #MP_D50_B500 = ('size_geom_mean', lambda x: (x<500).median())\n",
    " ).reset_index()\n",
    "\n",
    "mp_station['Concentration'] =  round(mp_station['Frequency']/ (mp_station['Mass'] * mp_station['Split']))\n",
    "mp_station['ConcentrationA500'] =  round(mp_station['FrequencyA500']/ (mp_station['Mass'] * mp_station['Split']))\n",
    "mp_station['ConcentrationB500'] =  round(mp_station['FrequencyB500']/ (mp_station['Mass'] * mp_station['Split']))\n",
    "mp_station.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e58473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpIrrStats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a8b49e5f468a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mMass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp_station\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sample'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Mass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmpIrr_Stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpIrrStats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mmpFibre_Stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpFibreStats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpIrrStats' is not defined"
     ]
    }
   ],
   "source": [
    "#import d50 values \n",
    "sed_d50 = pd.read_csv('Schlei_Sed_D50_new.csv',index_col=0)\n",
    "sed_63 = pd.read_csv('Schlei_Sed_D50_new.csv',index_col=0)\n",
    "\n",
    "#import ogranic matter size, TOC, Hg data\n",
    "sed_OM = pd.read_csv('Schlei_OM.csv',index_col=0)\n",
    "\n",
    "#import sampling log data\n",
    "slogs= pd.read_csv('Schlei_sed_sampling_log.csv',index_col=0)\n",
    "\n",
    "Dist_WWTP = pd.read_csv('Schlei_Sed_Dist_WWTP.csv',index_col=0)\n",
    "\n",
    "#merge with mp per station\n",
    "mp_sedStats = pd.merge(mp_station,slogs.reset_index(),on=['Sample'], how='left')\n",
    "mp_sedStats = pd.merge(mp_sedStats,sed_d50.reset_index(),on=['Sample'], how='left')\n",
    "mp_sedStats = pd.merge(mp_sedStats,sed_OM.reset_index(),on=['Sample'], how='left')\n",
    "mp_sedStats = pd.merge(mp_sedStats,Dist_WWTP.reset_index(),on=['Sample'], how='left')\n",
    "#mp_sedStats = pd.merge(mp_sedStats,Dist_WWTP.reset_index(),on=['Sample'], how='left')\n",
    "\n",
    "#merge with mp per polymer type and station\n",
    "#mp_sedStats_poly = pd.merge(mp_poly_station,sed_d50.reset_index(),on=['Sample'], how='left')\n",
    "\n",
    "#merge with mpFibre_Stats\n",
    "Mass = mp_station[['Sample','Mass']]\n",
    "\n",
    "mpIrr_Stats = pd.merge(mpIrrStats,Mass.reset_index(),on=['Sample'], how='left')\n",
    "mpFibre_Stats = pd.merge(mpFibreStats,Mass.reset_index(),on=['Sample'], how='left')\n",
    "\n",
    "##mpFibre_Stats = pd.merge(mpFibreStats,Mass.reset_index(),on=['Sample'], how='left')\n",
    "mpIrr_Stats['Concentration'] =  round(mpIrr_Stats['count']/ mpIrr_Stats['Mass'])\n",
    "mpIrr_sedStats = pd.merge(mpIrr_Stats,sed_d50.reset_index(),on=['Sample'], how='left')\n",
    "mpIrr_sedStats = pd.merge(mpIrr_sedStats,sed_OM.reset_index(),on=['Sample'], how='left')\n",
    "\n",
    "mpFibre_Stats['Concentration'] =  round(mpFibre_Stats['count']/ mpFibre_Stats['Mass'])\n",
    "mpFibre_sedStats = pd.merge(mpFibre_Stats,sed_d50.reset_index(),on=['Sample'], how='left')\n",
    "mpFibre_sedStats = pd.merge(mpFibre_sedStats,sed_OM.reset_index(),on=['Sample'], how='left')\n",
    "\n",
    "mp_sedStats.to_csv('MP_Stats_SchleiSediments.csv')\n",
    "mp_sedStats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c5ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary\n",
    "Regio_Sep =  {'Schlei_S1_15cm': 'inner',\n",
    "              'Schlei_S2': 'inner',\n",
    "              'Schlei_S3': 'inner',\n",
    "              'Schlei_S5': 'river',\n",
    "              'Schlei_S8': 'inner',\n",
    "              'Schlei_S10': 'inner',\n",
    "              'Schlei_S10_15cm': 'inner',\n",
    "              'Schlei_S11': 'inner',\n",
    "              'Schlei_S13': 'inner',\n",
    "              'Schlei_S14': 'outlier',\n",
    "              'Schlei_S15': 'inner',\n",
    "              'Schlei_S17': 'inner',\n",
    "              'Schlei_S19': 'outlier',\n",
    "              'Schlei_S22': 'outer',\n",
    "              'Schlei_S23': 'outer',\n",
    "              'Schlei_S24': 'outer', \n",
    "              'Schlei_S25': 'outer',\n",
    "              'Schlei_S26': 'outer',\n",
    "              'Schlei_S27': 'outer', \n",
    "              'Schlei_S30': 'outer', \n",
    "              'Schlei_S31': 'outer'}\n",
    "\n",
    "mp_sedStats = mp_sedStats.merge(pd.DataFrame.from_dict(Regio_Sep,orient='index',columns=['Regio_Sep']),left_on='Sample',right_index=True)\n",
    "#mp_sedStats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_MP = env_MP.merge(mp_sedStats[['Sample', 'TOC', 'Regio_Sep']], on='Sample')\n",
    "env_MP.rename(columns={'TOC': 'TOCs', 'Sampling_weight_[kg]': 'Sampling_weight'}, inplace=True)\n",
    "env_MP.drop(['Site_name', 'GPS_LON', 'GPS_LAT', 'Compartment',\n",
    "                      'Contributor', 'Project', 'Size_1_µm', 'Size_2_[µm]', 'Shape', 'Colour',\n",
    "                      'polymer_type', 'library_entry', 'lab_blank_ID', 'sample_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_bandwidth(data, kernel, bandwidths=10**np.linspace(0,2,100)):\n",
    "    grid = GridSearchCV(KernelDensity(kernel='gaussian'),\n",
    "                        {'bandwidth': bandwidths},\n",
    "                        cv=LeaveOneOut())\n",
    "    grid.fit(data[:, None]);\n",
    "    bw = grid.best_params_['bandwidth']\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kde(data, x_d=np.linspace(0,999,1000), optimise_bw=True , kernel='gaussian'):  # data should be 1D np-array, x_d is the discrete values where the probability density is evaluated, bw is the bandwidth to be used for the kernels\n",
    "    \n",
    "    bw = optimise_bandwidth(data, kernel) if optimise_bw else 50\n",
    "    \n",
    "    # instantiate and fit the KDE model\n",
    "    kde = KernelDensity(bandwidth=bw, kernel=kernel)\n",
    "    kde.fit(data[:, None])\n",
    "    # score_samples returns the log of the probability density\n",
    "    logprob = kde.score_samples(x_d[:, None])\n",
    "    kde_result = np.exp(logprob)\n",
    "    \n",
    "    return kde_result, bw\n",
    "\n",
    "#plt.fill_between(x_d, kde_result, alpha=0.5)\n",
    "#plt.plot(x, np.full_like(x, -0.001), '|k', markeredgewidth=1)\n",
    "#plt.xlim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = env_MP.loc[env_MP.Sample == 'Schlei_S10', 'size_geom_mean'].values\n",
    "\n",
    "SampleGroups = env_MP.groupby(['Sample'])\n",
    "\n",
    "kde_results = pd.DataFrame({'x_d': np.linspace(0,999,1000)})\n",
    "\n",
    "for SampleName, SampleGroup in SampleGroups:\n",
    "    x = SampleGroup.size_geom_mean.values\n",
    "    kde_result, bw = calculate_kde(x, optimise_bw=False)\n",
    "    \n",
    "    kde_results[SampleName] = kde_result\n",
    "    \n",
    "    print(f'{SampleName}:    bandwidth is {round(bw,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(kde_results.melt(id_vars=['x_d'])).mark_line().encode(\n",
    "    x='x_d',\n",
    "    y='value',\n",
    "    color='variable',\n",
    "    tooltip='variable'\n",
    ").interactive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
