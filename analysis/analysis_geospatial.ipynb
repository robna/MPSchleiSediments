{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')  # ignore warnings to avoid flooding the gridsearch output with repetitive messages (works for single cpu)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # could also filter with message='...'\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"  # ignore warnings to avoid flooding the gridsearch output with repetitive messages (works for parallel)\n",
    "try:  # if on phy-server local modules will not be found if their directory is not added to PATH\n",
    "    sys.path.append(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "    os.chdir(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact, fixed, widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import libpysal as lps\n",
    "import esda\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import hvplot.pandas  # noqa\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import seaborn as sns\n",
    "hv.extension('bokeh')\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from settings import Config\n",
    "import geo, geo_io\n",
    "from helpers import tqdm_joblib\n",
    "from cv import get_performance, performance, loocv_interp\n",
    "from plots import scatter_chart, model_pred_bars, gridplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create geodataframe from geojson file\n",
    "poly = geo_io.get_schlei()\n",
    "# poly.hvplot(crs=Config.baw_epsg, tiles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read predicted data from model run\n",
    "savestamp = '20231004_153340' #500rep run:'20231005_014730'  #'20230926_021644'  # '20230823_111917'  # '20230403_233901'   '20230501_172522'\n",
    "f = [c for c in Path('../data/exports/models/predictions').glob(f'{savestamp}*.csv')][0]\n",
    "target = f.name.split('_')[-2]\n",
    "station_data = pd.read_csv(f)\n",
    "station_data = gpd.GeoDataFrame(station_data, geometry=gpd.points_from_xy(station_data.LON, station_data.LAT), crs='EPSG:4326')\n",
    "\n",
    "station_data.to_crs(Config.baw_epsg, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## switch on to check what would be interpolated if only the original measured data points were available (i.e. no modelled stations)\n",
    "# station_data = station_data[~station_data.Concentration_observed.isna()].reset_index(drop=True)\n",
    "\n",
    "## switch on to interpolate with the single model predictions instead of the ensemble predictions\n",
    "# station_data[target][station_data[f'{target}_observed'].isna()] = station_data[f'{target}_predictedBySingleModel'][station_data[f'{target}_observed'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Most simple interpolation: using the stations' values for the whole Schlei area via Voronoi tesselation\n",
    "station_points = [(x,y) for x,y in zip(station_data.geometry.x, station_data.geometry.y)]\n",
    "voronoi_df, _ = lps.cg.voronoi_frames(station_points, clip=poly.geometry[0].geoms[0])\n",
    "voronoi_df.crs = station_data.crs\n",
    "station_data['Voronoi_Area'] = voronoi_df.geometry.area\n",
    "station_data['Voronoi_Sed_Mass'] = station_data.Voronoi_Area * Config.sediment_layer_depth * station_data.SedDryBulkDensity\n",
    "station_data['Voronoi_MP_Num'] =  station_data.Voronoi_Sed_Mass * station_data.Concentration\n",
    "station_data['Voronoi_MP_Mass'] = station_data.Voronoi_Sed_Mass * station_data.MassConcentration\n",
    "print(f'Based on Voronoi-regions: total MP in upper {Config.sediment_layer_depth*100} cm of Schlei sediments: {np.round(station_data.Voronoi_MP_Num.sum() / 1e12, 1)} Trillion particles with a combined mass of {np.round(station_data.Voronoi_MP_Mass.sum() / 1e12, 1)} tons')\n",
    "voronoi_df[target] = station_data[target]\n",
    "station_map = voronoi_df.hvplot(c=target, cmap='viridis', cnorm='eq_hist', line_alpha=0, crs=Config.baw_epsg, frame_width=600) * station_data.hvplot(color='white', fill_color='black', size=30, hover_cols=[col for col in station_data.columns if 'WWTP' not in col])\n",
    "station_map.opts(frame_width=1000, frame_height=700, active_tools = ['wheel_zoom'])\n",
    "\n",
    "# station_data = station_data.loc[\n",
    "#       (station_data.Sample!='S08')\n",
    "#     & (station_data.Sample!='S10')\n",
    "    # & (station_data.Sample!='20170425_G20')\n",
    "    # & (station_data.Sample!='S05')\n",
    "    # & (station_data.Sample!='S32')\n",
    "# ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridded interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose interpolation tool:\n",
    "\n",
    "        ## Any of: ['numpy_simple_idw',\n",
    "        ##          'numpy_rbf_idw',\n",
    "        ##          'scipy_rbf_idw',\n",
    "        ##          'scipy_griddata',\n",
    "        ##          'pykrige_ordkrig',\n",
    "        ##          'skgstat_ordkrig',\n",
    "        ##          'pygmt_xyz2grd',\n",
    "        ##          'load_external_interpol',\n",
    "        ##         ]\n",
    "\n",
    "\n",
    "tool = 'skgstat_ordkrig'  # must be in keys of Config.interpolation_methods\n",
    "if tool not in Config.interpolation_methods.keys():\n",
    "    raise KeyError('Chosen tool does not exist... Try again!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making the grid\n",
    "res = Config.interpolation_resolution  # grid resolution (pixel size in m)\n",
    "cell_area = res ** 2  # grid cell area in m² from cell width * cell height in m\n",
    "cell_sedVol = cell_area * Config.sediment_layer_depth  # volume of sediment layer considered in m³\n",
    "xgrid, ygrid, xmin, ymin, xmax, ymax = geo.make_grid(poly, res, round_grid_coords=True)\n",
    "print(f'grid bounds: xmin={xmin}, ymin={ymin}, xmax={xmax}, ymax={ymax}, grid shape: width: {xgrid.shape[1]}, height: {xgrid.shape[0]}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables to interpolate:\n",
    "vars = ['Concentration', 'MassConcentration', 'SedDryBulkDensity']\n",
    "\n",
    "### Single CPU calculation\n",
    "# grids = {var : geo.interclip(station_data, var, xgrid, ygrid, poly, tool) for var in tqdm(vars)}  # dict of grids of the interpolated variables\n",
    "\n",
    "### Multi CPU calculation (may crash du to Ram overflow for high grid resolutions)\n",
    "with tqdm_joblib(tqdm(desc=\"Parallel gridding...\", total=len(vars))) as progress_bar:\n",
    "    grids = {k: v for k, v in zip(vars, Parallel(n_jobs=len(vars))(delayed(geo.interclip)(station_data, var, xgrid, ygrid, poly, tool) for var in vars))}  # for some reason variogram plots don't show up when running parallelised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Plot grind in matplotlib\n",
    "# plt.imshow(target_clipped, cmap='terrain', interpolation='nearest')\n",
    "# plt.show()\n",
    "\n",
    "## Plot grid as interactive hvplot incl. coastline boundary\n",
    "hvgrid = gridplot(grids['Concentration'], xgrid, ygrid)\n",
    "hvgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarising intepolation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the generated MP grids at the station locations\n",
    "station_data.insert(4, f'Concentration_interpolated', geo.sample_array_raster(grids['Concentration'], xmin, ymax, res, station_data))\n",
    "station_data.insert(8, f'MassConcentration_interpolated', geo.sample_array_raster(grids['MassConcentration'], xmin, ymax, res, station_data))\n",
    "\n",
    "# Combine sediment and MP conc girds into abundance grid\n",
    "sedMass_grid = np.nan_to_num(grids['SedDryBulkDensity']) * cell_sedVol  # mass of sediment in each cell in kg, calculated from (interpolated) sediment dry bulk density (kg m⁻³) * volume of sediment per cell (m³)\n",
    "MPnum_grid = np.nan_to_num(grids['Concentration']) * sedMass_grid  # grid of target amounts (MP particles if target==Conentration; MP mass if target==MassConcentration)\n",
    "num_total = MPnum_grid.sum()\n",
    "MPmass_grid = np.nan_to_num(grids['MassConcentration']) * sedMass_grid\n",
    "mass_total = MPmass_grid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the performance of the prediction against the seen trainings data\n",
    "## OBS: this is a overly optimistic score and does not tell anything about how well the model can predict new data points. Use the scores from the NCV for that.\n",
    "## The difference between this score here and the NCV score, shows that the typical MP study scenario (low sample number) makes a crossvalidated score a neccesity.\n",
    "\n",
    "interact(\n",
    "    get_performance,\n",
    "        df=fixed(station_data), target=['Concentration', 'MassConcentration'], kind=['predicted', 'interpolated'], with_outliers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n', '='*100, '\\n')\n",
    "\n",
    "print('Summary of MP particles numbers:')\n",
    "\n",
    "print(f'Total MP particle numbers in upper {Config.sediment_layer_depth*100} cm of Schlei sediments: {np.round(num_total / 1e12, 1)} Trillion')\n",
    "print(f'MP particle number per m² and cm sediment depth: {round(num_total / poly.area[0] / (Config.sediment_layer_depth * 100))}')\n",
    "print(f'Schlei-wide MP number concentration as ratio of total MP / total sed mass: {round(num_total / sedMass_grid.sum())} particles / kg')\n",
    "print(f'Schlei-wide MP number concentration as mean of grid data (i.e. assuming equal sediment mass in all cells): {round(np.nanmean(grids[\"Concentration\"]))} particles / kg')\n",
    "print(f'Schlei-wide MP number concentration as mean of ALL stations (observed + predicted): {round(station_data[target].mean())} particles / kg')\n",
    "print(f'Schlei-wide MP number concentration as mean of OBSERVED stations only: {round(station_data.loc[station_data.Type==\"observed\", target].mean())} particles / kg')\n",
    "\n",
    "print('\\n', '='*100, '\\n')\n",
    "\n",
    "print('Summary of MP masses:')\n",
    "print(f'Total MP mass in upper {Config.sediment_layer_depth*100} cm of Schlei sediments: {np.round(mass_total / 1e12, 1)} tons')\n",
    "print(f'MP mass per m² and cm sediment depth: {round(mass_total / poly.area[0] / (Config.sediment_layer_depth * 100))} µg')\n",
    "print(f'Schlei-wide MP mass concentation as ratio of total MP mass / total sed mass: {round(mass_total / sedMass_grid.sum())} µg / kg')\n",
    "print(f'Schlei-wide MP mass concentation as mean of grid data (i.e. assuming equal sediment mass in all cells): {round(np.nanmean(grids[\"MassConcentration\"]))} µg / kg')\n",
    "print(f'Schlei-wide MP mass concentation as mean of ALL stations (observed + predicted): {round(station_data[\"MassConcentration\"].mean())} µg / kg')\n",
    "print(f'Schlei-wide MP mass concentation as mean of OBSERVED stations only: {round(station_data.loc[station_data.Type==\"observed\", \"MassConcentration\"].mean())} µg / kg')\n",
    "\n",
    "print('\\n', '='*100, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    model_pred_bars,\n",
    "        df = fixed(station_data),\n",
    "        target = ['Concentration', 'MassConcentration'],\n",
    "        domain = fixed(None),\n",
    "        )\n",
    "          \n",
    "# interact(\n",
    "#     model_pred_bars,\n",
    "#         df = fixed(station_data),\n",
    "#         target = ['Concentration', 'MassConcentration'],\n",
    "#         domain = widgets.FloatLogSlider(\n",
    "#             value=1,\n",
    "#             base=10,\n",
    "#             min=-2, # max exponent of base\n",
    "#             max=2, # min exponent of base\n",
    "#             step=0.1, # exponent step\n",
    "#             description='Y-axis scale',\n",
    "#             disabled=False,\n",
    "#             continuous_update=True,\n",
    "#             orientation='horizontal',\n",
    "#             )\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    scatter_chart,\n",
    "        df = fixed(station_data.loc[(station_data.Type=='observed')]),\n",
    "        x = ['Concentration_observed', 'Concentration_predicted', 'Concentration_interpolated', 'MassConcentration_observed', 'MassConcentration_predicted', 'MassConcentration_interpolated'],\n",
    "        y = ['Concentration_observed', 'Concentration_predicted', 'Concentration_interpolated', 'MassConcentration_observed', 'MassConcentration_predicted', 'MassConcentration_interpolated'],\n",
    "        color = 'outlier_excl', labels=[None, 'Sample'],\n",
    "        reg=['linear', 'pow', 'exp'], reg_groups=fixed(False),\n",
    "        equal_axes=fixed(False), identity = fixed(True),\n",
    "        linref=False, linref_slope=1.0, linref_intercept=fixed(0), mix_lines=fixed(False),\n",
    "        xtransform=fixed(False), ytransform=fixed(False), xscale = ['log', 'linear'], yscale = ['log', 'linear'],\n",
    "        title=fixed(''), width = fixed(400), height = fixed(400),\n",
    "        incl_params=fixed(False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving interpolated grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving raster to tiff file and reading it back in as rasterio dataset\n",
    "for var_name, grid in grids.items():\n",
    "    fp = f'../data/exports/models/predictions/interpolated/{savestamp}_{var_name}_{tool}_{int(res)}x{int(res)}'\n",
    "    Config.interpolation_methods[tool]['var_name'] = var_name\n",
    "    geo_io.grid_save(grid, fp+'.tif', (xmin, ymax), tags=Config.interpolation_methods[tool])\n",
    "    hvplot.save(gridplot(grid, xgrid, ygrid), fp+'.html', resources='INLINE')  # Saving hvplot of grid to interactive html\n",
    "    with rio.open(fp+'.tif') as rasta:\n",
    "        # out_img, out_transform = mask(rasta, poly.geometry[0].geoms, nodata=np.nan)\n",
    "        print(rasta.tags())\n",
    "        show(rasta, cmap='terrain', norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOCV of interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Config.interpolation_methods[tool]['plot'] = False  # turn of plotting in case interpolation method want to plot...\n",
    "station_data[f'{target}_LOOCV'] = loocv_interp(station_data, target, xgrid, ygrid, res, poly, tool, n_jobs=72, verbose=0)\n",
    "\n",
    "print('\\n', f'Performance calculation is based on {station_data.shape[0]} ŷhat-vs-y pairs.')\n",
    "performance(station_data.loc[:, target], station_data.loc[:, f'{target}_LOOCV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_chart(\n",
    "    df = station_data.loc[~station_data.iloc[:,-1].isna()],\n",
    "    x = f'{target}',\n",
    "    y = f'{target}_LOOCV',\n",
    "    color = 'outlier_excl', \n",
    "    equal_axes=True, identity = True,\n",
    "    incl_params=False, width=400, height=400\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridding other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridf_orig = gpd.GeoDataFrame({target: grids['Concentration'].ravel()}, geometry=gpd.points_from_xy(xgrid.ravel(), ygrid.ravel()), crs=Config.baw_epsg)\n",
    "# gridf = gridf_orig.loc[~gridf_orig[target].isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridf = geo.get_depth(gridf, label='Depth')\n",
    "# gridf.loc[gridf.Depth < 0, 'Depth'] = 0  # removing artefacts from sampleing from one grid to the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridf['Dist_Land'] = geo.get_distance_to_shore(gridf.to_crs('EPSG:4326').geometry.x, gridf.to_crs('EPSG:4326').geometry.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridf.plot(\n",
    "#     marker='o', markersize=0.1,\n",
    "#     column=\"Depth\",\n",
    "#     cmap='terrain_r',\n",
    "#     legend=True,\n",
    "#     # scheme=\"quantiles\",\n",
    "#     figsize=(15, 10),\n",
    "#     missing_kwds={\n",
    "#         \"color\": \"lightgrey\",\n",
    "#         # \"edgecolor\": \"red\",\n",
    "#         # \"hatch\": \"///\"\n",
    "#         \"label\": \"Missing values\",\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridf_orig['Depth'] = gridf.Depth  # values will only be inserted where indeces match\n",
    "# gridf_orig['Dist_Land'] = gridf.Dist_Land  # values will only be inserted where indeces match\n",
    "# Depth_grid = gridf_orig.Depth.values.reshape(xgrid.shape)  # turn geodataframe back into grid array\n",
    "# Dist_Land_grid = gridf_orig.Dist_Land.values.reshape(xgrid.shape)  # turn geodataframe back into grid array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to file...\n",
    "# geo_io.grid_save(Depth_grid,f'../data/Depth_epsg{Config.baw_epsg}_{res}x{res}.tif', (xmin, ymax))\n",
    "# geo_io.grid_save(Dist_Land_grid,f'../data/Dist_Land_epsg{Config.baw_epsg}_{res}x{res}.tif', (xmin, ymax))\n",
    "# gridf.to_csv(f'../data/grid_{res}m_ForPredictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w =  lps.weights.Voronoi.from_dataframe(station_data)  # generating spatial weights object\n",
    "# w.transform = 'r'  # making weights row-standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Check if a property is spatially auto-corralated\n",
    "# property = target  # 'Depth', 'Dist_Land', 'Concentratration', etc...\n",
    "\n",
    "# np.random.seed(12345)\n",
    "# mi = esda.moran.Moran(station_data[property], w)\n",
    "# print(f\"Moran's I: {mi.I}\")\n",
    "# sns.kdeplot(mi.sim, fill=True)\n",
    "# plt.vlines(mi.I, 0, 1, color='r')\n",
    "# plt.vlines(mi.EI, 0,1)\n",
    "# plt.xlabel(f\"Moran's I (p = {mi.p_sim})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact(\n",
    "#     scatter_chart,\n",
    "#         df = fixed(station_data),\n",
    "#         x = station_data.select_dtypes([np.number]).columns,\n",
    "#         y = station_data.select_dtypes([np.number]).columns,\n",
    "#         color = 'outlier_excl', labels=[None, 'Sample'],\n",
    "#         reg=['linear', 'pow', 'exp'], reg_groups=fixed(False),\n",
    "#         equal_axes=fixed(False), identity = fixed(False),\n",
    "#         linref=fixed(False), linref_slope=fixed(1.0), linref_intercept=fixed(0), mix_lines=fixed(False),\n",
    "#         xtransform=fixed(False), ytransform=fixed(False), xscale = ['log', 'linear'], yscale = ['log', 'linear'],\n",
    "#         title=fixed(''), width = fixed(400), height = fixed(400),\n",
    "#         incl_params=fixed(False)\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPSchleiSediments-venv",
   "language": "python",
   "name": "mpschleisediments-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
