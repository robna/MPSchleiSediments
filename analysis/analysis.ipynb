{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from scipy import stats\n",
    "\n",
    "try:  # if on phy-server local modules will not be found if their directory is not added to PATH\n",
    "    import sys\n",
    "    sys.path.append(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "    import os\n",
    "    os.chdir(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import prepare_data\n",
    "import outliers\n",
    "import KDE_utils\n",
    "import correlations\n",
    "from components import PCA, PCOA, biplot\n",
    "import glm\n",
    "from settings import shortnames, Config\n",
    "\n",
    "# alt.renderers.enable('altair_viewer')  # use to display altair charts externally in browser instead of inline (only activate in non-vega-compatible IDE like pycharm)\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and prepare data\n",
    "**Before running, check the computational parameters in settings.py**\n",
    "\n",
    "Nomenclature:\n",
    "- *pdd*: particle domain data = data is particle based, meaning one entry (row) corresponds to one particle and one feature (column) corresponds to one property observed for that particle\n",
    "- *sdd*: sample domain data = data is sample based, meaning one entry (row) corresponds to one sample and one feature (column) corresponds to one property observed for that sample\n",
    "- *mp*: data on microplastics\n",
    "- *sed*: data on sediments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% loading data\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 3 samples with less than 18 particles.\n",
      "Sample\n",
      "Schlei_S24    16.5\n",
      "Schlei_S31    11.0\n",
      "Schlei_S5      9.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# What happened so far: DB extract and blank procedure. Now import resulting MP data from csv\n",
    "mp_pdd = pd.read_csv('../data/env_MP_clean_list_SchleiSediments.csv', index_col=0)\n",
    "mp_pdd = prepare_data.mass_conversion(mp_pdd)  # calculate particle weights\n",
    "mp_pdd = outliers.low_freq_out(mp_pdd)  # remove low frequency outliers\n",
    "# mp_pdd = mp_pdd.loc[mp_pdd.Shape=='irregular']  # filter to only use fibres or irregulars\n",
    "mp_pdd['polymer_type'] = mp_pdd['polymer_type'].map(shortnames).fillna(mp_pdd['polymer_type'])  # use abbreviations for polymer names but retain original names for polymers not present in shortnames\n",
    "\n",
    "# Also import sediment data (sediment frequencies per size bin from master sizer export)\n",
    "grainsize_iow = pd.read_csv('../data/sediment_grainsize_IOW_vol_log-cau_not-closed.csv')\n",
    "grainsize_cau = pd.read_csv('../data/sediment_grainsize_CAU_vol_log-cau_closed.csv')\n",
    "grainsize_cau.dropna(subset=grainsize_cau.iloc[:,1:].columns, how='all', inplace=True)  # CAU sediment data contains empty sammples which are dropped here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_pdd = mp_pdd.loc[~mp_pdd.polymer_type.isin(['AcrR', 'AlkR', 'EPX'])]  # exclude paint flakes\n",
    "# mp_pdd = mp_pdd.loc[~mp_pdd.Sample.isin(['Schlei_S10_15cm'])]  # exclude paint flakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the binning structure of the imported sediment data and optionally rebin it (make binning coarser) for faster computation\n",
    "grainsize_iow, sed_lower_boundaries = prepare_data.sediment_preps(grainsize_iow)\n",
    "grainsize_cau, _ = prepare_data.sediment_preps(grainsize_cau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% data wrangling\n"
    }
   },
   "outputs": [],
   "source": [
    "# ...some data wrangling to prepare particle domain data and sample domain data for MP and combine with certain sediment aggregates.\n",
    "mp_sdd = prepare_data.aggregate_SDD(mp_pdd)\n",
    "mp_added_sed_sdd = prepare_data.add_sediment(mp_sdd)\n",
    "# mp_added_metadata_pdd = prepare_data.sdd2pdd(mp_added_sed_sdd, mp_pdd)  # TODO: not used. Remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_added_sed_sdd['pred_ConcentrationA500'] = np.exp(0.505 + 0.0452 * mp_added_sed_sdd['perc MUD'] + 0.0249 * 2.22 * mp_added_sed_sdd['TOC'])\n",
    "\n",
    "alt.Chart(mp_added_sed_sdd).mark_point().encode(x='ConcentrationA500',y='pred_ConcentrationA500',tooltip='Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = prepare_data.aggregate_SDD(mp_pdd.groupby(['Sample', 'polymer_type'])).merge(mp_added_sed_sdd[['Sample', 'Dist_WWTP', 'regio_sep']], on='Sample')\n",
    "# comp['polymer_type'] = comp.Shape\n",
    "\n",
    "com = comp.pivot(index='Sample', columns=['polymer_type'], values=['Concentration']).droplevel(0,axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCoA: Proportion explained: \n",
      " PC1    0.538526\n",
      "PC2    0.148061\n",
      "dtype: float64    PCoA Total: 0.6865872931002923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nibor/.local/share/virtualenvs/MPSchleiSediments-bSFBF4Xj/lib/python3.9/site-packages/skbio/stats/ordination/_principal_coordinate_analysis.py:143: RuntimeWarning: The result contains negative eigenvalues. Please compare their magnitude with the magnitude of some of the largest positive eigenvalues. If the negative ones are smaller, it's probably safe to ignore them, but if they are large in magnitude, the results won't be useful. See the Notes section for more details. The smallest eigenvalue is -0.0384604463190555 and the largest is 0.8122294361419842.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "scor, load, expl = PCOA(com, 2)  # call either PCA or PCOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# biplot(scor, load, expl, mp_added_sed_sdd, 'PC1', 'PC2', sc='regio_sep', lc='polymer_type', ntf=7, normalise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = 'sphinx_gallery'\n",
    "# fig = px.scatter(scor.rename_axis(index='Sample').reset_index().merge(comp[['Sample', 'Dist_WWTP', 'regio_sep']], on='Sample'),\n",
    "#                     x='PC1',\n",
    "#                     y='PC2',\n",
    "#                     #z='PC3',  # when uncommenting: use px.scatter_3d instead of px.scatter\n",
    "#                     color='Dist_WWTP',\n",
    "#                     color_continuous_scale='Greys',\n",
    "#                     hover_name=\"Sample\")\n",
    "\n",
    "# # resize markers\n",
    "# fig.update_traces(marker=dict(size=10,\n",
    "#                               line=dict(width=2,\n",
    "#                                         color='DarkSlateGrey')),\n",
    "#                   selector=dict(mode='markers'))\n",
    "\n",
    "# # change size and move colorbar\n",
    "# fig.update_layout(autosize=False, width=1000, height=800,\n",
    "#                   coloraxis_colorbar=dict(yanchor=\"top\", y=1, x=0, ticks=\"outside\"))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## MP particle size distributions\n",
    "\n",
    "*This calculates probability density distributions for MP sizes. These are used to estimate the abundances of MP of specific size ranges, which can then be investigated for correlations to environmental parameters such as TOC or sediment grain size properties.*\n",
    "**Before running, check the computational parameters in settings.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% calculating probability densities\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schlei_S8:    bandwidth is 50                        \r"
     ]
    }
   ],
   "source": [
    "# KDEs for probability of finding a MP particle in a specific size bin are calculated.\n",
    "size_pdfs = KDE_utils.per_sample_kde(mp_pdd, sed_lower_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MP concentrations for each single-step size bin\n",
    "mp_size_conc = KDE_utils.probDens2conc(size_pdfs, mp_sdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MP and sediment abundances per size bin are equalised (only samples and bins contained in both of the are kept).\n",
    "# They are then melted and merged into MPsedMelted.\n",
    "mp_size_conc, grainsize_iow, mp_sed_melt = prepare_data.equalise_mp_and_sed(mp_size_conc, grainsize_iow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sediment size bin dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "# SEDpc, SEDexp, SEDload = sed_pca(SEDext.T)\n",
    "# sedpc, sedexp, sedload = sed_pca(grainsize_iow)\n",
    "\n",
    "# To see a loadings plot use:\n",
    "# sedload_df = pd.DataFrame(sedload, columns=['PC1', 'PC2', 'PC3'], index = np.unique(np.concatenate(np.char.split(sed_size_freqs.index.values.astype(str), '_')).ravel().astype(int))[:-1]).T\n",
    "# sedload_df.T.plot()  # x-axis corresponds to lower boundary of size bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCoA: Proportion explained: \n",
      " PC1    0.786809\n",
      "PC2    0.115434\n",
      "dtype: float64    PCoA Total: 0.9022432758660464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nibor/.local/share/virtualenvs/MPSchleiSediments-bSFBF4Xj/lib/python3.9/site-packages/skbio/stats/ordination/_principal_coordinate_analysis.py:143: RuntimeWarning: The result contains negative eigenvalues. Please compare their magnitude with the magnitude of some of the largest positive eigenvalues. If the negative ones are smaller, it's probably safe to ignore them, but if they are large in magnitude, the results won't be useful. See the Notes section for more details. The smallest eigenvalue is -0.02489288420698408 and the largest is 3.18013878352681.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# PCoA\n",
    "\n",
    "# sedpco = sed_pcoa(grainsize_iow, num_coords = 2)\n",
    "# sedpco = sed_pcoa(grainsize_iow.append(grainsize_cau), num_coords = 2)\n",
    "sedpco, sedloads, sedexpl = PCOA(grainsize_iow, num=2)\n",
    "\n",
    "# Plot PCo1 and PCo2\n",
    "# alt.Chart(sedpco.merge(mp_added_sed_sdd, left_index=True, right_on='Sample').reset_index()).mark_point().encode(\n",
    "#     x='PC1',\n",
    "#     y='PC2',\n",
    "#     color='D50',\n",
    "#     tooltip='index'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set_theme(style=\"white\")\n",
    "\n",
    "# df = sedpco.merge(mp_added_sed_sdd, left_index=True, right_on='Sample')\n",
    "# corrmat = df.corr()\n",
    "\n",
    "# # Generate a mask for the upper triangle\n",
    "# mask = np.triu(np.ones_like(corrmat, dtype=bool))\n",
    "\n",
    "# # Set up the matplotlib figure\n",
    "# f, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "# # Generate a custom diverging colormap\n",
    "# cmap = sns.diverging_palette(230, 10, as_cmap=True)\n",
    "\n",
    "# # Draw the heatmap with the mask and correct aspect ratio\n",
    "# sns.heatmap(corrmat, mask=mask, vmax=.3, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alt.Chart(df).mark_circle().encode(\n",
    "#     alt.X(alt.repeat(\"column\"), type='quantitative'),\n",
    "#     alt.Y(alt.repeat(\"row\"), type='quantitative'),\n",
    "#     color='regio_sep:N',\n",
    "#     tooltip=['Sample']\n",
    "# ).properties(\n",
    "#     width=200,\n",
    "#     height=200\n",
    "# ).repeat(\n",
    "#     row=['D50', 'smaller63', 'MoM_ari_MEAN', 'MoM_ari_SORTING', 'MoM_ari_SKEWNESS', 'MoM_ari_KURTOSIS', 'MoM_geo_MEAN', 'MoM_geo_SORTING',\n",
    "#        'MoM_geo_SKEWNESS', 'MoM_geo_KURTOSIS', 'MoM_log_MEAN', 'MoM_log_SORTING', 'MoM_log_SKEWNESS', 'MoM_log_KURTOSIS',\n",
    "#        'FW_geo_MEAN', 'FW_geo_SORTING', 'FW_geo_SKEWNESS', 'FW_geo_KURTOSIS', 'FW_log_MEAN', 'FW_log_SORTING', 'FW_log_SKEWNESS', 'FW_log_KURTOSIS',\n",
    "#        'MODE 1 (µm)', 'MODE 2 (µm)', 'MODE 3 (µm)', 'D10 (µm)', 'D50 (µm)', 'D90 (µm)', '(D90 div D10) (µm)', '(D90 - D10) (µm)', '(D75 div D25) (µm)', '(D75 - D25) (µm)', 'perc GRAVEL', 'perc SAND', 'perc MUD',\n",
    "#        'perc V COARSE SAND', 'perc COARSE SAND', 'perc MEDIUM SAND', 'perc FINE SAND', 'perc V FINE SAND', 'perc V COARSE SILT', 'perc COARSE SILT',\n",
    "#        'perc MEDIUM SILT', 'perc FINE SILT', 'perc V FINE SILT', 'perc CLAY', 'Dx 50', 'TOC', 'Hg'],\n",
    "#     column=['PC1', 'PC2']\n",
    "# ).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18c8bfe50>\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:          Concentration   No. Observations:                   28\n",
      "Model:                            GLM   Df Residuals:                       25\n",
      "Model Family:                 Poisson   Df Model:                            2\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -43423.\n",
      "Date:                Mon, 14 Feb 2022   Deviance:                       86582.\n",
      "Time:                        19:58:16   Pearson chi2:                 1.29e+05\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      7.7647      0.007   1180.201      0.000       7.752       7.778\n",
      "Dist_WWTP  -3.724e-05   3.81e-07    -97.738      0.000    -3.8e-05   -3.65e-05\n",
      "TOC            0.1123      0.001    202.787      0.000       0.111       0.113\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a generalized linear model (GLM) to predict the microplastic concentration from the predictors\n",
    "\n",
    "glm_input = mp_added_sed_sdd.merge(sedpco, left_on='Sample', right_index=True)\n",
    "\n",
    "glm_res = glm.glm(glm_input)\n",
    "print(glm_res.summary())\n",
    "# glm_res.predict(glm_input.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff188bded60>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff188bdec10>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18c530eb0>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18f7a0070>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18c913f10>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18d619e80>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff194559790>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18c913f10>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff1944ea730>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18c55ad60>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18dcd7310>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff194559070>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18dcd7310>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18c52ed60>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18c55ad60>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18d619e80>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff1944ea970>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff1945031f0>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff1944ea610>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff188bb8070>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18c533df0>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff1945031f0>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18949f250>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff188bb80a0>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18949f250>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff1944ea700>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff188bb8070>\n",
      "\n",
      "<statsmodels.genmod.families.family.Poisson object at 0x7ff18dbb4d90>\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.sandbox.tools.cross_val import LeaveOneOut, split\n",
    "\n",
    "\n",
    "loo = LeaveOneOut(mp_added_sed_sdd.shape[0])\n",
    "pred = pd.DataFrame(columns=['Sample', 'pred'])\n",
    "for train_index, test_index in loo:\n",
    "    # this could be used for doing loo-cross-val, if using array-based instead formula-and-dataframe based model:\n",
    "    #X_train, X_test, y_train, y_test = split(train_index, test_index, X, y)  \n",
    "    \n",
    "    train = glm_input.loc[train_index,:]\n",
    "    test =  glm_input.loc[test_index,:]\n",
    "    glm_res = glm.glm(train)\n",
    "    predi = pd.concat([test.Sample, glm_res.predict(test).rename('pred')], axis=1)\n",
    "    pred = pd.concat([pred, predi])\n",
    "    \n",
    "pred.loc[:, Config.glm_formula.split(' ~')[0]] = glm_input.loc[:, Config.glm_formula.split(' ~')[0]]\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "rmse = np.sqrt(mean_squared_error(pred.iloc[:,-1], pred.pred))\n",
    "mae = \n",
    "r2 = r2_score(pred.iloc[:,-1], pred.pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost model\n",
    "\n",
    "data = mp_added_sed_sdd.merge(sedpco, left_on='Sample', right_index=True).set_index('Sample').copy()\n",
    "\n",
    "y = data.pop('Concentration') # Target vector in pd.Series format\n",
    "X = data.loc[:, ['MoM_ari_MEAN', 'MoM_ari_SORTING',\n",
    "       'MoM_ari_SKEWNESS', 'MoM_ari_KURTOSIS', 'MoM_geo_MEAN',\n",
    "       'MoM_geo_SORTING', 'MoM_geo_SKEWNESS', 'MoM_geo_KURTOSIS',\n",
    "       'MoM_log_MEAN', 'MoM_log_SORTING', 'MoM_log_SKEWNESS',\n",
    "       'MoM_log_KURTOSIS', 'perc GRAVEL', 'perc SAND',\n",
    "       'perc MUD', 'perc V COARSE SAND', 'perc COARSE SAND', 'perc MEDIUM SAND',\n",
    "       'perc FINE SAND', 'perc V FINE SAND', 'perc V COARSE SILT',\n",
    "       'perc COARSE SILT', 'perc MEDIUM SILT', 'perc FINE SILT',\n",
    "       'perc V FINE SILT', 'perc CLAY', 'OM_D50', 'TOC', 'Hg', 'Dist_WWTP',\n",
    "       'PC1', 'PC2']] # Feature matrix in pd.DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making train and test sets for both X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, shuffle=True)\n",
    "# Instantiate an XGBoost object with hyperparameters\n",
    "xgb_reg = xgb.XGBRegressor(col_sample=10, alpha=0.5, max_depth=2, n_estimators=1000, n_jobs=2,\n",
    "                           objective='reg:squarederror', booster='gbtree',\n",
    "                           random_state=42, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with train data sets\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_reg.predict(X_test) # Predictions\n",
    "y_true = y_test # True values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mse(y_true, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "R_squared = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\nRMSE: \", np.round(RMSE, 2))\n",
    "print()\n",
    "print(\"R-Squared: \", np.round(R_squared, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "\n",
    "y_pred_as_series = pd.Series(y_pred, index=X_test.index, dtype=int)\n",
    "\n",
    "xpl = SmartExplainer() # Creating xpl object\n",
    "xpl.compile(x=X_test, model=xgb_reg, y_pred=y_pred_as_series)\n",
    "app = xpl.run_app() # Launch the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MP and sediment size range combination correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sum abundances in size bins for all possible combinations. Basically create all possible rebinnings and stack them into one DF\n",
    "# MPext = prepare_data.combination_sums(mp_size_conc.copy().T).T  # TODO: using transposed df's here, because combination_sums is not yet turned around: it takes features in rows and samples in columns...\n",
    "SEDext= prepare_data.combination_sums(grainsize_cau.copy().T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Altair size range correlation (PC~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pc='PC2'\n",
    "\n",
    "pc2gs_corr = pd.DataFrame(SEDext.corrwith(sedpco[pc], method='pearson'), columns=['pearson'])\n",
    "pc2gs_corr['spearman'] = SEDext.corrwith(sedpco[pc], method='spearman')\n",
    "pc2gs_corr['size_low'] = pc2gs_corr.index.str.split('_').str[0].astype(float)\n",
    "pc2gs_corr['size_up'] = pc2gs_corr.index.str.split('_').str[1].astype(float)\n",
    "pc2gs_corr['size_dif'] = pc2gs_corr['size_up'] - pc2gs_corr['size_low']\n",
    "\n",
    "df = sedpco.join(SEDext).melt(id_vars=['PC1','PC2'], ignore_index=False)\n",
    "df['size_low'] = df.variable.str.split('_').str[0].astype(float)\n",
    "df['size_up'] = df.variable.str.split('_').str[1].astype(float)\n",
    "df['size_dif'] = df['size_up'] - df['size_low']\n",
    "\n",
    "x_init = float(SEDext.iloc[:,pc2gs_corr.pearson.argmax()].name.split('_')[0])\n",
    "y_init = float(SEDext.iloc[:,pc2gs_corr.pearson.argmax()].name.split('_')[1])\n",
    "pts = alt.selection(type=\"single\", encodings=['x','y'], init={'x': x_init, 'y': y_init})\n",
    "\n",
    "heatmap = alt.Chart(pc2gs_corr.reset_index()).mark_circle().encode(\n",
    "    x = alt.X('size_low', scale=alt.Scale(type='log')),\n",
    "    y = alt.Y('size_up', scale=alt.Scale(type='log')),\n",
    "    color = alt.condition(alt.datum.pearson == pc2gs_corr.pearson.max(),\n",
    "                          alt.value('orange'),\n",
    "                          alt.Color('pearson', scale=alt.Scale(scheme='redblue', domain=[-1,1]))),\n",
    "    # size = alt.condition(alt.datum.pearson == pc2gs_corr.pearson.max(),\n",
    "    #                       alt.value('10'),\n",
    "    #                       alt.value('5')),\n",
    "    tooltip = ['pearson', 'spearman', 'size_low', 'size_dif', 'size_up']\n",
    ").add_selection(pts\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600\n",
    ").interactive()\n",
    "\n",
    "\n",
    "scatter = alt.Chart(df.reset_index()).mark_point().encode(\n",
    "    x=pc,\n",
    "    y='value',\n",
    "    tooltip='index'\n",
    ")\n",
    "\n",
    "RegLine = scatter.transform_regression(\n",
    "    pc, 'value', method=\"linear\",\n",
    ").mark_line(\n",
    "    color=\"red\"\n",
    ")\n",
    "\n",
    "RegParams = scatter.transform_regression(\n",
    "    pc, 'value', method=\"linear\", params=True\n",
    ").mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(20),  # pixels from top\n",
    "    text='params:N'\n",
    ").transform_calculate(\n",
    "    params='\"R² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[1] * 100)/100 + \"x\" + \" + \" + round(datum.coef[0] * 10)/10'\n",
    ")\n",
    "\n",
    "text0 = scatter.mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(60),  # pixels from top\n",
    "    text=alt.value('Size bin:')\n",
    ")\n",
    "\n",
    "text1 = scatter.mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(80),  # pixels from top\n",
    "    text='variable'\n",
    ")\n",
    "\n",
    "scat_plot = alt.layer(\n",
    "    scatter, RegLine, RegParams, text0, text1\n",
    ").transform_filter(pts\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "alt.hconcat(\n",
    "    heatmap,\n",
    "    scat_plot\n",
    ").resolve_legend(\n",
    "    color=\"independent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Altair size range correlation (MP~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MPsedExt = prepare_data.merge_size_ranges(MPext, 'MP', SEDext, 'SED', cart_prod=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brush1 = alt.selection_interval(name=\"brush1\", encodings=['y'])\n",
    "brush2 = alt.selection_interval(name=\"brush2\", encodings=['x'])\n",
    "\n",
    "step = sed_lower_boundaries[1] - sed_lower_boundaries[0]\n",
    "\n",
    "scatter = alt.Chart(MPsedExt\n",
    ").transform_calculate(\n",
    "    b1l=f'floor((isDefined(brush1.y) ? (brush1.y[0][0]) : 1) / {step}) * {step}',\n",
    "    b1u=f'ceil((isDefined(brush1.y) ? (brush1.y[0][1]) : 1) / {step}) * {step}',\n",
    "    b2l=f'floor((isDefined(brush2.x) ? (brush2.x[0][0]) : 1) / {step}) * {step}',\n",
    "    b2u=f'ceil((isDefined(brush2.x) ? (brush2.x[0][1]) : 1) / {step}) * {step}',\n",
    ").mark_point().encode(\n",
    "    x = 'SED',\n",
    "    y = 'MP',\n",
    "    tooltip = 'sample:N'\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP >= datum.b1l) &&'\n",
    "    '(datum.upper_MP <= datum.b1u) &&'\n",
    "    '(datum.lower_SED >= datum.b2l) &&'\n",
    "    '(datum.upper_SED <= datum.b2u)'\n",
    ")\n",
    "    \n",
    "\n",
    "RegLine = scatter.transform_regression(\n",
    "    'SED', 'MP', method=\"linear\",\n",
    ").mark_line(\n",
    "    color=\"red\"\n",
    ")\n",
    "\n",
    "\n",
    "RegParams = scatter.transform_regression(\n",
    "    'SED', 'MP', method=\"linear\", params=True\n",
    ").mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(120),  # pixels from left\n",
    "    y=alt.value(20),  # pixels from top\n",
    "    text='params:N'\n",
    ").transform_calculate(\n",
    "    params='\"r² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[1] * 100)/100 + \"x\" + \" + \" + round(datum.coef[0] * 10)/10'\n",
    ")\n",
    "\n",
    "\n",
    "MP = alt.Chart(MPsedExt).mark_line().encode(\n",
    "    x = 'mean(MP)',\n",
    "    y = alt.X('lower_MP', scale=alt.Scale(type='linear'))\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP == datum.lower_SED) && \\\n",
    "     (datum.upper_MP == datum.upper_SED)'\n",
    ").add_selection(\n",
    "    brush1\n",
    ").properties(\n",
    "    height = 300,\n",
    "    width = 100\n",
    ")\n",
    "\n",
    "\n",
    "sed = alt.Chart(MPsedExt).mark_line().encode(\n",
    "    x = alt.X('lower_SED', scale=alt.Scale(type='linear')),\n",
    "    y = 'mean(SED)'\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP == datum.lower_SED) &&'\n",
    "    '(datum.upper_MP == datum.upper_SED)'\n",
    ").add_selection(\n",
    "    brush2\n",
    ").properties(\n",
    "    height = 100,\n",
    "    width = 400\n",
    ")\n",
    "\n",
    "\n",
    "MP | (scatter + RegLine + RegParams) & sed\n",
    "\n",
    "# chart = MP | scatter & sed\n",
    "# chart#.save('chart.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Size range correlation matrix (MP~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a correlation matrix containing Pearson correlation coefficients for all combinations of any original or summed bins of MP and sediments.\n",
    "corrMat = np.corrcoef(MPext,SEDext)\n",
    "corrMat = corrMat[:len(MPext), len(SEDext):]  # only take upper right quadrant of correlation matrix\n",
    "\n",
    "corrMatDF = pd.DataFrame(corrMat, index=MPext.index, columns=SEDext.index)  # turn np array into df\n",
    "# corrMatDF.rename('MP_{}'.format, axis=0, inplace=True)  # add a prefix for 'MP' to each row label\n",
    "# corrMatDF.rename('SED_{}'.format, axis=1, inplace=True)  # add a prefix for 'sediment' to each column label\n",
    "corrMatDF.index.name = 'MP'\n",
    "corrMatDF.columns.name = 'SED'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run a cross-correlation for each sample between MP and sediment size distribution curve shapes.\n",
    "crosscorr_results = pd.DataFrame()\n",
    "\n",
    "for label, content in df_range_conc.items():\n",
    "    datax = content\n",
    "    datay = grainsize_iow[label]\n",
    "    #best = correlations.crosscorr(datax, datay)\n",
    "        \n",
    "#     lags = range(-int(len(datax)/2), int(len(datax)/2)+1)\n",
    "    lags = range(-50,0)\n",
    "    df_r = pd.DataFrame(lags, columns = ['shifted'])\n",
    "    \n",
    "#     r_pear = [datax.corr(datay.shift(lag)) for lag in lags]\n",
    "#     df_r['pearson_r'] = r_pear\n",
    "    r_spear = [stats.spearmanr(np.array(datax),np.array(datay.shift(lag)), nan_policy = 'omit') for lag in lags]\n",
    "    df_r['spearman_r'] = r_spear\n",
    "    \n",
    "    \n",
    "    best = df_r.copy().loc[df_r['spearman_r'] == df_r['spearman_r'].max()]\n",
    "    best['Sample'] = label\n",
    "    crosscorr_results = crosscorr_results.append(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MP-to-Scalar correlation (e.g. TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(mp_added_sed_sdd).mark_point().encode(\n",
    "    alt.X(alt.repeat(\"column\"), type='quantitative'),\n",
    "    y = 'Concentration',\n",
    "    color = 'Regio_Sep',\n",
    "    tooltip = 'Sample'\n",
    ").repeat(\n",
    "    column=['D50', 'TOC', 'Dist_WWTP', 'Mass', 'Split']\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(mp_added_sed_sdd, x='Dist_WWTP', y='D50', z='Concentration',\n",
    "                    color='TOC', symbol='regio_sep', hover_name=\"Sample\",\n",
    "                    color_continuous_scale=px.colors.sequential.turbid_r)\n",
    "\n",
    "# resize markers\n",
    "fig.update_traces(marker=dict(size=4,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "\n",
    "# change size and move colorbar\n",
    "fig.update_layout(autosize=False, width=1000, height=800,\n",
    "                  coloraxis_colorbar=dict(yanchor=\"top\", y=1, x=0, ticks=\"outside\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate correlation between all size bins (or their summed up combinations) of MP abundances and a scalar predictor.\n",
    "# Possible predictors are: 'TOC', 'Hg', 'Dist_WWTP' or different sediment grain size properties (D50, below 63, etc.). See column labels of sdd_MP_sed for a full list.\n",
    "bestLower, bestUpper, df_r = correlations.predictorcorr(df_range_conc, mp_added_sed_sdd.set_index('Sample'), 'TOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Heatmap correlation coefficients from the single predictor correlation\n",
    "alt.renderers.enable('html')\n",
    "\n",
    "alt.Chart(df_r).mark_point().encode(\n",
    "    x='lower_size',\n",
    "    y='upper_size',\n",
    "    color=alt.Color(\"r\", scale=alt.Scale(domain=[0.5, 0.6])),\n",
    "    tooltip=['r', 'lower_size', 'upper_size']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "#####USED only for testing external function inside NB: #####\n",
    "step = (Config.upper_size_limit - Config.lower_size_limit) / Config.kde_steps\n",
    "df_r = pd.DataFrame(columns=['lower_size', 'upper_size', 'r', 'p'])\n",
    "\n",
    "for i in [10]:\n",
    "    for j in [1000]:\n",
    "        size_sum = size_pdfs.loc[(size_pdfs.x_d >= i) & (size_pdfs.x_d < j)].sum()\n",
    "        size_sum.drop('x_d', inplace=True)\n",
    "        range_prob = size_sum * step\n",
    "        range_conc = range_prob * mp_added_sed_sdd.set_index('Sample').Concentration\n",
    "\n",
    "        r = stats.pearsonr(range_conc, mp_added_sed_sdd.set_index('Sample').TOC)\n",
    "        df_r.loc[len(df_r)] = [i, j, r[0], r[1]]\n",
    "        print(f'Correlating TOC with size range            [{i},        {j}]                ', end=\"\\r\", flush=True)\n",
    "\n",
    "print(df_r.loc[df_r.r == df_r.r.max()])\n",
    "bestLower, bestUpper = df_r.loc[df_r.r == df_r.r.max()].iloc[0, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Property-property-plot with MP against single predictor incl. reg line \n",
    "kd = alt.Chart(pd.DataFrame([range_conc, mp_added_sed_sdd.set_index('Sample').TOC]).T.reset_index()).mark_point().encode(\n",
    "    x='TOC',\n",
    "    y='Unnamed 0',\n",
    "    color='index',\n",
    "    tooltip='index'\n",
    ")\n",
    "\n",
    "Reg_Line = kd.transform_regression('TOC', 'Unnamed 0', method=\"linear\",\n",
    "                                  ).mark_line(color=\"red\")\n",
    "\n",
    "Reg_Params = kd.transform_regression('TOC', 'Unnamed 0', method=\"linear\", params=True\n",
    "                                    ).mark_text(align='left', lineBreak='\\n').encode(\n",
    "        x=alt.value(120),  # pixels from left\n",
    "        y=alt.value(20),  # pixels from top\n",
    "        text='params:N'\n",
    "    ).transform_calculate(\n",
    "        params='\"r² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[0] * 10)/10 + \" + e ^ (\" + round(datum.coef[1] * 10000)/10000 + \"x\" + \")\" + \\n + \" \"'\n",
    "    )\n",
    "\n",
    "kd + Reg_Line + Reg_Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daf = grainsize_iow.reset_index().melt(id_vars='index', value_name='value')\n",
    "daf['size'] = daf['index'].str.split('_').str[0]\n",
    "daf['category'] = 'sediment'\n",
    "\n",
    "daff = df_range_conc.reset_index().melt(id_vars='index', value_name='value')\n",
    "daff['size'] = daf['index'].str.split('_').str[0]\n",
    "daff['category'] = 'MP'\n",
    "\n",
    "df = pd.concat([daf, daff]).drop(columns=['index'])\n",
    "# df = daf.merge(daff, on =['sample', 'size', 'index']).drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dropdown = alt.binding_select(options=list(df['sample'].unique()), name='select sample ')\n",
    "selection = alt.selection_single(fields=['sample'],\n",
    "                                 bind=input_dropdown,\n",
    "                                 #init={'select_': 'Schlei_S8'}\n",
    "                                )\n",
    "\n",
    "base = alt.Chart(df).mark_line().encode(\n",
    "    x=alt.X('size:Q'),\n",
    "    y=alt.Y('value:Q'),\n",
    "    color='category',\n",
    "#     shape='category',\n",
    "#     detail='category'\n",
    "# ).transform_window(\n",
    "#     cuml='sum(value)',\n",
    "#     groupby=['sample']\n",
    ").transform_filter(\n",
    "    alt.FieldRangePredicate(field='size', range=[50, 990])\n",
    "# ).properties(\n",
    "#     width=180,\n",
    "#     height=180\n",
    "# ).facet(\n",
    "#     facet='sample',\n",
    "#     columns=6\n",
    "# ).resolve_scale(\n",
    "#     y='independent'\n",
    ")\n",
    "\n",
    "\n",
    "mps = base.mark_line(color='blue').transform_filter(\n",
    "    alt.FieldEqualPredicate(field='category', equal='MP')\n",
    ")\n",
    "seds = base.mark_line(color='yellow').transform_filter(\n",
    "    alt.FieldEqualPredicate(field='category', equal='sediment')\n",
    ")\n",
    "\n",
    "alt.layer(mps, seds).resolve_scale(\n",
    "    y = 'independent'\n",
    ").add_selection(\n",
    "    selection\n",
    ").transform_filter(\n",
    "    selection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = alt.Chart(df).encode(\n",
    "    alt.X('size:Q', axis=alt.Axis(title=None))\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ")\n",
    "\n",
    "mps = base.mark_line(stroke='#57A44C', interpolate='monotone').encode(\n",
    "    alt.Y('MP:Q', axis=alt.Axis(title='MP', titleColor='#57A44C'))\n",
    ")\n",
    "\n",
    "seds = base.mark_line(stroke='#5276A7', interpolate='monotone').encode(\n",
    "    alt.Y('sediment:Q', axis=alt.Axis(title='sediment', titleColor='#5276A7'))\n",
    ")\n",
    "\n",
    "alt.layer(mps, seds).resolve_scale(\n",
    "    y = 'independent'\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ").facet(\n",
    "    facet='sample',\n",
    "    columns=6\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = daf.shift(100).merge(daff, on =['sample', 'size', 'index']).drop(columns=['index'])\n",
    "alt.Chart(df).mark_point().encode(\n",
    "    x=alt.X('value_x', scale=alt.Scale(type='linear')),\n",
    "    y=alt.X('value_y', scale=alt.Scale(type='linear')),\n",
    "    color=alt.Color('size:Q', scale=alt.Scale(scheme=\"viridis\"))\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=150\n",
    ").facet(\n",
    "    facet='sample',\n",
    "    columns=6\n",
    ").resolve_scale(\n",
    "    y='independent',\n",
    "    x='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'x': range(9),\n",
    "    'y': [1, 2, 3, 4, 5, 4, 3, 2, 1]\n",
    "})\n",
    "\n",
    "brush = alt.selection_interval(name=\"brush\", encodings=['x'])\n",
    "alt.Chart(data).mark_line().add_selection(brush).transform_calculate(\n",
    "    scaled_by_brush_width='datum.y * (isDefined(brush.x) ? (brush.x[1] - brush.x[0]) : 1)'\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    y='scaled_by_brush_width:Q'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f52180fe46b99599fa7a0c38aeb9ade3a59b8665d580284bd71af4d35515bb12"
  },
  "kernelspec": {
   "display_name": "MPSchleiSediments-bSFBF4Xj",
   "language": "python",
   "name": "mpschleisediments-bsfbf4xj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}