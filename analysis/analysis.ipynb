{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from scipy import stats\n",
    "\n",
    "try:  # if on phy-server local modules will not be found if their directory is not added to PATH\n",
    "    import sys\n",
    "    sys.path.append(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "    import os\n",
    "    os.chdir(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import prepare_data\n",
    "import KDE_utils\n",
    "import correlations\n",
    "from pcoa import sed_pcoa\n",
    "from pca import sed_pca\n",
    "import glm\n",
    "from settings import shortnames, Config\n",
    "\n",
    "# alt.renderers.enable('altair_viewer')  # use to display altair charts externally in browser instead of inline (only activate in non-vega-compatible IDE like pycharm)\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data\n",
    "**Before running, check the computational parameters in settings.py**\n",
    "\n",
    "Nomenclature:\n",
    "- *pdd*: particle domain data = data is particle based, meaning one entry (row) corresponds to one particle and one feature (column) corresponds to one property observed for that particle\n",
    "- *sdd*: sample domain data = data is sample based, meaning one entry (row) corresponds to one sample and one feature (column) corresponds to one property observed for that sample\n",
    "- *mp*: data on microplastics\n",
    "- *sed*: data on sediments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% loading data\n"
    }
   },
   "outputs": [],
   "source": [
    "# What happened so far: DB extract and blank procedure. Now import resulting MP data from csv\n",
    "mp_pdd = pd.read_csv('../data/env_MP_clean_list_SchleiSediments.csv', index_col=0)\n",
    "\n",
    "# Also import sediment data (sediment frequencies per size bin from master sizer export)\n",
    "grainsize_iow = pd.read_csv('../data/sediment_grainsize_IOW_vol_log-cau_not-closed.csv')\n",
    "grainsize_cau = pd.read_csv('../data/sediment_grainsize_CAU_vol_log-cau_closed.csv')\n",
    "grainsize_cau.dropna(subset=grainsize_cau.iloc[:,1:].columns, how='all', inplace=True)  # CAU sediment data contains empty sammples which are dropped here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the binning structure of the imported sediment data and optionally rebin it (make binning coarser) for faster computation\n",
    "grainsize_iow, sed_lower_boundaries = prepare_data.sediment_preps(grainsize_iow)\n",
    "grainsize_cau, _ = prepare_data.sediment_preps(grainsize_cau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% data wrangling\n"
    }
   },
   "outputs": [],
   "source": [
    "# ...some data wrangling to prepare particle domain data and sample domain data for MP and combine with certain sediment aggregates.\n",
    "mp_sdd = prepare_data.aggregate_SDD(mp_pdd)\n",
    "mp_added_sed_sdd = prepare_data.add_sediment(mp_sdd)\n",
    "# mp_added_metadata_pdd = prepare_data.sdd2pdd(mp_added_sed_sdd, mp_pdd)  # TODO: not used. Remove?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## MP particle size distributions\n",
    "\n",
    "*This calculates probability density distributions for MP sizes. These are used to estimate the abundances of MP of specific size ranges, which can then be investigated for correlations to environmental parameters such as TOC or sediment grain size properties.*\n",
    "**Before running, check the computational parameters in settings.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% calculating probability densities\n"
    }
   },
   "outputs": [],
   "source": [
    "# KDEs for probability of finding a MP particle in a specific size bin are calculated.\n",
    "size_pdfs = KDE_utils.per_sample_kde(mp_pdd, sed_lower_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MP concentrations for each single-step size bin\n",
    "mp_size_conc = KDE_utils.probDens2conc(size_pdfs, mp_sdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MP and sediment abundances per size bin are equalised (only samples and bins contained in both of the are kept).\n",
    "# They are then melted and merged into MPsedMelted.\n",
    "mp_size_conc, grainsize_iow, mp_sed_melt = prepare_data.equalise_mp_and_sed(mp_size_conc, grainsize_iow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sediment size bin dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "# SEDpc, SEDexp, SEDload = sed_pca(SEDext.T)\n",
    "# sedpc, sedexp, sedload = sed_pca(grainsize_iow)\n",
    "\n",
    "# To see a loadings plot use:\n",
    "# sedload_df = pd.DataFrame(sedload, columns=['PC1', 'PC2', 'PC3'], index = np.unique(np.concatenate(np.char.split(sed_size_freqs.index.values.astype(str), '_')).ravel().astype(int))[:-1]).T\n",
    "# sedload_df.T.plot()  # x-axis corresponds to lower boundary of size bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCoA\n",
    "\n",
    "# sedpco = sed_pcoa(grainsize_iow, num_coords = 2)\n",
    "# sedpco = sed_pcoa(grainsize_iow.append(grainsize_cau), num_coords = 2)\n",
    "sedpco = sed_pcoa(grainsize_cau, num_coords = 2)\n",
    "\n",
    "# Plot PCo1 and PCo2\n",
    "# alt.Chart(sedpco.merge(mp_added_sed_sdd, left_index=True, right_on='Sample').reset_index()).mark_point().encode(\n",
    "#     x='PC1',\n",
    "#     y='PC2',\n",
    "#     color='D50',\n",
    "#     tooltip='index'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set_theme(style=\"white\")\n",
    "\n",
    "# df = sedpco.merge(mp_added_sed_sdd, left_index=True, right_on='Sample')\n",
    "# corrmat = df.corr()\n",
    "\n",
    "# # Generate a mask for the upper triangle\n",
    "# mask = np.triu(np.ones_like(corrmat, dtype=bool))\n",
    "\n",
    "# # Set up the matplotlib figure\n",
    "# f, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "# # Generate a custom diverging colormap\n",
    "# cmap = sns.diverging_palette(230, 10, as_cmap=True)\n",
    "\n",
    "# # Draw the heatmap with the mask and correct aspect ratio\n",
    "# sns.heatmap(corrmat, mask=mask, vmax=.3, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alt.Chart(df).mark_circle().encode(\n",
    "#     alt.X(alt.repeat(\"column\"), type='quantitative'),\n",
    "#     alt.Y(alt.repeat(\"row\"), type='quantitative'),\n",
    "#     color='regio_sep:N',\n",
    "#     tooltip=['Sample']\n",
    "# ).properties(\n",
    "#     width=200,\n",
    "#     height=200\n",
    "# ).repeat(\n",
    "#     row=['D50', 'smaller63', 'MoM_ari_MEAN', 'MoM_ari_SORTING', 'MoM_ari_SKEWNESS', 'MoM_ari_KURTOSIS', 'MoM_geo_MEAN', 'MoM_geo_SORTING',\n",
    "#        'MoM_geo_SKEWNESS', 'MoM_geo_KURTOSIS', 'MoM_log_MEAN', 'MoM_log_SORTING', 'MoM_log_SKEWNESS', 'MoM_log_KURTOSIS',\n",
    "#        'FW_geo_MEAN', 'FW_geo_SORTING', 'FW_geo_SKEWNESS', 'FW_geo_KURTOSIS', 'FW_log_MEAN', 'FW_log_SORTING', 'FW_log_SKEWNESS', 'FW_log_KURTOSIS',\n",
    "#        'MODE 1 (µm)', 'MODE 2 (µm)', 'MODE 3 (µm)', 'D10 (µm)', 'D50 (µm)', 'D90 (µm)', '(D90 div D10) (µm)', '(D90 - D10) (µm)', '(D75 div D25) (µm)', '(D75 - D25) (µm)', 'perc GRAVEL', 'perc SAND', 'perc MUD',\n",
    "#        'perc V COARSE SAND', 'perc COARSE SAND', 'perc MEDIUM SAND', 'perc FINE SAND', 'perc V FINE SAND', 'perc V COARSE SILT', 'perc COARSE SILT',\n",
    "#        'perc MEDIUM SILT', 'perc FINE SILT', 'perc V FINE SILT', 'perc CLAY', 'Dx 50', 'TOC', 'Hg'],\n",
    "#     column=['PC1', 'PC2']\n",
    "# ).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### XGBoosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost model\n",
    "\n",
    "data = mp_added_sed_sdd.merge(sedpco, left_on='Sample', right_index=True).set_index('Sample').copy()\n",
    "\n",
    "y = data.pop('Concentration') # Target vector in pd.Series format\n",
    "X = data.loc[:, ['MoM_ari_MEAN', 'MoM_ari_SORTING',\n",
    "       'MoM_ari_SKEWNESS', 'MoM_ari_KURTOSIS', 'MoM_geo_MEAN',\n",
    "       'MoM_geo_SORTING', 'MoM_geo_SKEWNESS', 'MoM_geo_KURTOSIS',\n",
    "       'MoM_log_MEAN', 'MoM_log_SORTING', 'MoM_log_SKEWNESS',\n",
    "       'MoM_log_KURTOSIS', 'perc GRAVEL', 'perc SAND',\n",
    "       'perc MUD', 'perc V COARSE SAND', 'perc COARSE SAND', 'perc MEDIUM SAND',\n",
    "       'perc FINE SAND', 'perc V FINE SAND', 'perc V COARSE SILT',\n",
    "       'perc COARSE SILT', 'perc MEDIUM SILT', 'perc FINE SILT',\n",
    "       'perc V FINE SILT', 'perc CLAY', 'OM_D50', 'TOC', 'Hg', 'Dist_WWTP',\n",
    "       'PC1', 'PC2']] # Feature matrix in pd.DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making train and test sets for both X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, shuffle=True)\n",
    "# Instantiate an XGBoost object with hyperparameters\n",
    "xgb_reg = xgb.XGBRegressor(col_sample=10, alpha=0.5, max_depth=2, n_estimators=1000, n_jobs=2,\n",
    "                           objective='reg:squarederror', booster='gbtree',\n",
    "                           random_state=42, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with train data sets\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_reg.predict(X_test) # Predictions\n",
    "y_true = y_test # True values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mse(y_true, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "R_squared = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\nRMSE: \", np.round(RMSE, 2))\n",
    "print()\n",
    "print(\"R-Squared: \", np.round(R_squared, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "\n",
    "y_pred_as_series = pd.Series(y_pred, index=X_test.index, dtype=int)\n",
    "\n",
    "xpl = SmartExplainer() # Creating xpl object\n",
    "xpl.compile(x=X_test, model=xgb_reg, y_pred=y_pred_as_series)\n",
    "app = xpl.run_app() # Launch the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### GLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a generalized linear model (GLM) to predict the microplastic concentration from the predictors\n",
    "\n",
    "glm_input = mp_added_sed_sdd.merge(sedpco, left_on='Sample', right_index=True)\n",
    "\n",
    "glm_res = glm.glm(glm_input)\n",
    "print(glm_res.summary())\n",
    "# glm_res.predict(glm_input.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.tools.cross_val import LeaveOneOut, split\n",
    "loo = LeaveOneOut(mp_added_sed_sdd.shape[0])\n",
    "for train_index, test_index in loo:\n",
    "    # this could be used for doing loo-cross-val, if using array-based instead formula-and-dataframe based model:\n",
    "    #X_train, X_test, y_train, y_test = cross_val.split(train_index, test_index, X, y)  \n",
    "    \n",
    "    current_input = glm_input.loc[train_index,:]\n",
    "    glm_res = glm.glm(current_input)\n",
    "    # TODO: predict... something like pred = glm_res.predict(glm_input.loc[test_index,:]\n",
    "    # TODO: get error (RMSE?) from prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MP and sediment size range combination correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sum abundances in size bins for all possible combinations. Basically create all possible rebinnings and stack them into one DF\n",
    "# MPext = prepare_data.combination_sums(mp_size_conc.copy().T).T  # TODO: using transposed df's here, because combination_sums is not yet turned around: it takes features in rows and samples in columns...\n",
    "SEDext= prepare_data.combination_sums(grainsize_cau.copy().T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Altair size range correlation (PC~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pc='PC2'\n",
    "\n",
    "pc2gs_corr = pd.DataFrame(SEDext.corrwith(sedpco[pc], method='pearson'), columns=['pearson'])\n",
    "pc2gs_corr['spearman'] = SEDext.corrwith(sedpco[pc], method='spearman')\n",
    "pc2gs_corr['size_low'] = pc2gs_corr.index.str.split('_').str[0].astype(float)\n",
    "pc2gs_corr['size_up'] = pc2gs_corr.index.str.split('_').str[1].astype(float)\n",
    "pc2gs_corr['size_dif'] = pc2gs_corr['size_up'] - pc2gs_corr['size_low']\n",
    "\n",
    "df = sedpco.join(SEDext).melt(id_vars=['PC1','PC2'], ignore_index=False)\n",
    "df['size_low'] = df.variable.str.split('_').str[0].astype(float)\n",
    "df['size_up'] = df.variable.str.split('_').str[1].astype(float)\n",
    "df['size_dif'] = df['size_up'] - df['size_low']\n",
    "\n",
    "x_init = float(SEDext.iloc[:,pc2gs_corr.pearson.argmax()].name.split('_')[0])\n",
    "y_init = float(SEDext.iloc[:,pc2gs_corr.pearson.argmax()].name.split('_')[1])\n",
    "pts = alt.selection(type=\"single\", encodings=['x','y'], init={'x': x_init, 'y': y_init})\n",
    "\n",
    "heatmap = alt.Chart(pc2gs_corr.reset_index()).mark_circle().encode(\n",
    "    x = alt.X('size_low', scale=alt.Scale(type='log')),\n",
    "    y = alt.Y('size_up', scale=alt.Scale(type='log')),\n",
    "    color = alt.condition(alt.datum.pearson == pc2gs_corr.pearson.max(),\n",
    "                          alt.value('orange'),\n",
    "                          alt.Color('pearson', scale=alt.Scale(scheme='redblue', domain=[-1,1]))),\n",
    "    # size = alt.condition(alt.datum.pearson == pc2gs_corr.pearson.max(),\n",
    "    #                       alt.value('10'),\n",
    "    #                       alt.value('5')),\n",
    "    tooltip = ['pearson', 'spearman', 'size_low', 'size_dif', 'size_up']\n",
    ").add_selection(pts\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600\n",
    ").interactive()\n",
    "\n",
    "\n",
    "scatter = alt.Chart(df.reset_index()).mark_point().encode(\n",
    "    x=pc,\n",
    "    y='value',\n",
    "    tooltip='index'\n",
    ")\n",
    "\n",
    "RegLine = scatter.transform_regression(\n",
    "    pc, 'value', method=\"linear\",\n",
    ").mark_line(\n",
    "    color=\"red\"\n",
    ")\n",
    "\n",
    "RegParams = scatter.transform_regression(\n",
    "    pc, 'value', method=\"linear\", params=True\n",
    ").mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(20),  # pixels from top\n",
    "    text='params:N'\n",
    ").transform_calculate(\n",
    "    params='\"R² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[1] * 100)/100 + \"x\" + \" + \" + round(datum.coef[0] * 10)/10'\n",
    ")\n",
    "\n",
    "text0 = scatter.mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(60),  # pixels from top\n",
    "    text=alt.value('Size bin:')\n",
    ")\n",
    "\n",
    "text1 = scatter.mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(80),  # pixels from top\n",
    "    text='variable'\n",
    ")\n",
    "\n",
    "scat_plot = alt.layer(\n",
    "    scatter, RegLine, RegParams, text0, text1\n",
    ").transform_filter(pts\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "alt.hconcat(\n",
    "    heatmap,\n",
    "    scat_plot\n",
    ").resolve_legend(\n",
    "    color=\"independent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Altair size range correlation (MP~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MPsedExt = prepare_data.merge_size_ranges(MPext, 'MP', SEDext, 'SED', cart_prod=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brush1 = alt.selection_interval(name=\"brush1\", encodings=['y'])\n",
    "brush2 = alt.selection_interval(name=\"brush2\", encodings=['x'])\n",
    "\n",
    "step = sed_lower_boundaries[1] - sed_lower_boundaries[0]\n",
    "\n",
    "scatter = alt.Chart(MPsedExt\n",
    ").transform_calculate(\n",
    "    b1l=f'floor((isDefined(brush1.y) ? (brush1.y[0][0]) : 1) / {step}) * {step}',\n",
    "    b1u=f'ceil((isDefined(brush1.y) ? (brush1.y[0][1]) : 1) / {step}) * {step}',\n",
    "    b2l=f'floor((isDefined(brush2.x) ? (brush2.x[0][0]) : 1) / {step}) * {step}',\n",
    "    b2u=f'ceil((isDefined(brush2.x) ? (brush2.x[0][1]) : 1) / {step}) * {step}',\n",
    ").mark_point().encode(\n",
    "    x = 'SED',\n",
    "    y = 'MP',\n",
    "    tooltip = 'sample:N'\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP >= datum.b1l) &&'\n",
    "    '(datum.upper_MP <= datum.b1u) &&'\n",
    "    '(datum.lower_SED >= datum.b2l) &&'\n",
    "    '(datum.upper_SED <= datum.b2u)'\n",
    ")\n",
    "    \n",
    "\n",
    "RegLine = scatter.transform_regression(\n",
    "    'SED', 'MP', method=\"linear\",\n",
    ").mark_line(\n",
    "    color=\"red\"\n",
    ")\n",
    "\n",
    "\n",
    "RegParams = scatter.transform_regression(\n",
    "    'SED', 'MP', method=\"linear\", params=True\n",
    ").mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(120),  # pixels from left\n",
    "    y=alt.value(20),  # pixels from top\n",
    "    text='params:N'\n",
    ").transform_calculate(\n",
    "    params='\"r² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[1] * 100)/100 + \"x\" + \" + \" + round(datum.coef[0] * 10)/10'\n",
    ")\n",
    "\n",
    "\n",
    "MP = alt.Chart(MPsedExt).mark_line().encode(\n",
    "    x = 'mean(MP)',\n",
    "    y = alt.X('lower_MP', scale=alt.Scale(type='linear'))\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP == datum.lower_SED) && \\\n",
    "     (datum.upper_MP == datum.upper_SED)'\n",
    ").add_selection(\n",
    "    brush1\n",
    ").properties(\n",
    "    height = 300,\n",
    "    width = 100\n",
    ")\n",
    "\n",
    "\n",
    "sed = alt.Chart(MPsedExt).mark_line().encode(\n",
    "    x = alt.X('lower_SED', scale=alt.Scale(type='linear')),\n",
    "    y = 'mean(SED)'\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP == datum.lower_SED) &&'\n",
    "    '(datum.upper_MP == datum.upper_SED)'\n",
    ").add_selection(\n",
    "    brush2\n",
    ").properties(\n",
    "    height = 100,\n",
    "    width = 400\n",
    ")\n",
    "\n",
    "\n",
    "MP | (scatter + RegLine + RegParams) & sed\n",
    "\n",
    "# chart = MP | scatter & sed\n",
    "# chart#.save('chart.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Size range correlation matrix (MP~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a correlation matrix containing Pearson correlation coefficients for all combinations of any original or summed bins of MP and sediments.\n",
    "corrMat = np.corrcoef(MPext,SEDext)\n",
    "corrMat = corrMat[:len(MPext), len(SEDext):]  # only take upper right quadrant of correlation matrix\n",
    "\n",
    "corrMatDF = pd.DataFrame(corrMat, index=MPext.index, columns=SEDext.index)  # turn np array into df\n",
    "# corrMatDF.rename('MP_{}'.format, axis=0, inplace=True)  # add a prefix for 'MP' to each row label\n",
    "# corrMatDF.rename('SED_{}'.format, axis=1, inplace=True)  # add a prefix for 'sediment' to each column label\n",
    "corrMatDF.index.name = 'MP'\n",
    "corrMatDF.columns.name = 'SED'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run a cross-correlation for each sample between MP and sediment size distribution curve shapes.\n",
    "crosscorr_results = pd.DataFrame()\n",
    "\n",
    "for label, content in df_range_conc.items():\n",
    "    datax = content\n",
    "    datay = grainsize_iow[label]\n",
    "    #best = correlations.crosscorr(datax, datay)\n",
    "        \n",
    "#     lags = range(-int(len(datax)/2), int(len(datax)/2)+1)\n",
    "    lags = range(-50,0)\n",
    "    df_r = pd.DataFrame(lags, columns = ['shifted'])\n",
    "    \n",
    "#     r_pear = [datax.corr(datay.shift(lag)) for lag in lags]\n",
    "#     df_r['pearson_r'] = r_pear\n",
    "    r_spear = [stats.spearmanr(np.array(datax),np.array(datay.shift(lag)), nan_policy = 'omit') for lag in lags]\n",
    "    df_r['spearman_r'] = r_spear\n",
    "    \n",
    "    \n",
    "    best = df_r.copy().loc[df_r['spearman_r'] == df_r['spearman_r'].max()]\n",
    "    best['Sample'] = label\n",
    "    crosscorr_results = crosscorr_results.append(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MP-to-Scalar correlation (e.g. TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(mp_added_sed_sdd).mark_point().encode(\n",
    "    alt.X(alt.repeat(\"column\"), type='quantitative'),\n",
    "    y = 'Concentration',\n",
    "    color = 'Regio_Sep',\n",
    "    tooltip = 'Sample'\n",
    ").repeat(\n",
    "    column=['D50', 'TOC', 'Dist_WWTP', 'Mass', 'Split']\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(mp_added_sed_sdd, x='Dist_WWTP', y='D50', z='Concentration',\n",
    "                    color='TOC', symbol='regio_sep', hover_name=\"Sample\",\n",
    "                    color_continuous_scale=px.colors.sequential.turbid_r)\n",
    "\n",
    "# resize markers\n",
    "fig.update_traces(marker=dict(size=4,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "\n",
    "# change size and move colorbar\n",
    "fig.update_layout(autosize=False, width=1000, height=800,\n",
    "                  coloraxis_colorbar=dict(yanchor=\"top\", y=1, x=0, ticks=\"outside\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate correlation between all size bins (or their summed up combinations) of MP abundances and a scalar predictor.\n",
    "# Possible predictors are: 'TOC', 'Hg', 'Dist_WWTP' or different sediment grain size properties (D50, below 63, etc.). See column labels of sdd_MP_sed for a full list.\n",
    "bestLower, bestUpper, df_r = correlations.predictorcorr(df_range_conc, mp_added_sed_sdd.set_index('Sample'), 'TOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Heatmap correlation coefficients from the single predictor correlation\n",
    "alt.renderers.enable('html')\n",
    "\n",
    "alt.Chart(df_r).mark_point().encode(\n",
    "    x='lower_size',\n",
    "    y='upper_size',\n",
    "    color=alt.Color(\"r\", scale=alt.Scale(domain=[0.5, 0.6])),\n",
    "    tooltip=['r', 'lower_size', 'upper_size']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "#####USED only for testing external function inside NB: #####\n",
    "step = (Config.upper_size_limit - Config.lower_size_limit) / Config.kde_steps\n",
    "df_r = pd.DataFrame(columns=['lower_size', 'upper_size', 'r', 'p'])\n",
    "\n",
    "for i in [10]:\n",
    "    for j in [1000]:\n",
    "        size_sum = size_pdfs.loc[(size_pdfs.x_d >= i) & (size_pdfs.x_d < j)].sum()\n",
    "        size_sum.drop('x_d', inplace=True)\n",
    "        range_prob = size_sum * step\n",
    "        range_conc = range_prob * mp_added_sed_sdd.set_index('Sample').Concentration\n",
    "\n",
    "        r = stats.pearsonr(range_conc, mp_added_sed_sdd.set_index('Sample').TOC)\n",
    "        df_r.loc[len(df_r)] = [i, j, r[0], r[1]]\n",
    "        print(f'Correlating TOC with size range            [{i},        {j}]                ', end=\"\\r\", flush=True)\n",
    "\n",
    "print(df_r.loc[df_r.r == df_r.r.max()])\n",
    "bestLower, bestUpper = df_r.loc[df_r.r == df_r.r.max()].iloc[0, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Property-property-plot with MP against single predictor incl. reg line \n",
    "kd = alt.Chart(pd.DataFrame([range_conc, mp_added_sed_sdd.set_index('Sample').TOC]).T.reset_index()).mark_point().encode(\n",
    "    x='TOC',\n",
    "    y='Unnamed 0',\n",
    "    color='index',\n",
    "    tooltip='index'\n",
    ")\n",
    "\n",
    "Reg_Line = kd.transform_regression('TOC', 'Unnamed 0', method=\"linear\",\n",
    "                                  ).mark_line(color=\"red\")\n",
    "\n",
    "Reg_Params = kd.transform_regression('TOC', 'Unnamed 0', method=\"linear\", params=True\n",
    "                                    ).mark_text(align='left', lineBreak='\\n').encode(\n",
    "        x=alt.value(120),  # pixels from left\n",
    "        y=alt.value(20),  # pixels from top\n",
    "        text='params:N'\n",
    "    ).transform_calculate(\n",
    "        params='\"r² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[0] * 10)/10 + \" + e ^ (\" + round(datum.coef[1] * 10000)/10000 + \"x\" + \")\" + \\n + \" \"'\n",
    "    )\n",
    "\n",
    "kd + Reg_Line + Reg_Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daf = grainsize_iow.reset_index().melt(id_vars='index', value_name='value')\n",
    "daf['size'] = daf['index'].str.split('_').str[0]\n",
    "daf['category'] = 'sediment'\n",
    "\n",
    "daff = df_range_conc.reset_index().melt(id_vars='index', value_name='value')\n",
    "daff['size'] = daf['index'].str.split('_').str[0]\n",
    "daff['category'] = 'MP'\n",
    "\n",
    "df = pd.concat([daf, daff]).drop(columns=['index'])\n",
    "# df = daf.merge(daff, on =['sample', 'size', 'index']).drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dropdown = alt.binding_select(options=list(df['sample'].unique()), name='select sample ')\n",
    "selection = alt.selection_single(fields=['sample'],\n",
    "                                 bind=input_dropdown,\n",
    "                                 #init={'select_': 'Schlei_S8'}\n",
    "                                )\n",
    "\n",
    "base = alt.Chart(df).mark_line().encode(\n",
    "    x=alt.X('size:Q'),\n",
    "    y=alt.Y('value:Q'),\n",
    "    color='category',\n",
    "#     shape='category',\n",
    "#     detail='category'\n",
    "# ).transform_window(\n",
    "#     cuml='sum(value)',\n",
    "#     groupby=['sample']\n",
    ").transform_filter(\n",
    "    alt.FieldRangePredicate(field='size', range=[50, 990])\n",
    "# ).properties(\n",
    "#     width=180,\n",
    "#     height=180\n",
    "# ).facet(\n",
    "#     facet='sample',\n",
    "#     columns=6\n",
    "# ).resolve_scale(\n",
    "#     y='independent'\n",
    ")\n",
    "\n",
    "\n",
    "mps = base.mark_line(color='blue').transform_filter(\n",
    "    alt.FieldEqualPredicate(field='category', equal='MP')\n",
    ")\n",
    "seds = base.mark_line(color='yellow').transform_filter(\n",
    "    alt.FieldEqualPredicate(field='category', equal='sediment')\n",
    ")\n",
    "\n",
    "alt.layer(mps, seds).resolve_scale(\n",
    "    y = 'independent'\n",
    ").add_selection(\n",
    "    selection\n",
    ").transform_filter(\n",
    "    selection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = alt.Chart(df).encode(\n",
    "    alt.X('size:Q', axis=alt.Axis(title=None))\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ")\n",
    "\n",
    "mps = base.mark_line(stroke='#57A44C', interpolate='monotone').encode(\n",
    "    alt.Y('MP:Q', axis=alt.Axis(title='MP', titleColor='#57A44C'))\n",
    ")\n",
    "\n",
    "seds = base.mark_line(stroke='#5276A7', interpolate='monotone').encode(\n",
    "    alt.Y('sediment:Q', axis=alt.Axis(title='sediment', titleColor='#5276A7'))\n",
    ")\n",
    "\n",
    "alt.layer(mps, seds).resolve_scale(\n",
    "    y = 'independent'\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ").facet(\n",
    "    facet='sample',\n",
    "    columns=6\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = daf.shift(100).merge(daff, on =['sample', 'size', 'index']).drop(columns=['index'])\n",
    "alt.Chart(df).mark_point().encode(\n",
    "    x=alt.X('value_x', scale=alt.Scale(type='linear')),\n",
    "    y=alt.X('value_y', scale=alt.Scale(type='linear')),\n",
    "    color=alt.Color('size:Q', scale=alt.Scale(scheme=\"viridis\"))\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=150\n",
    ").facet(\n",
    "    facet='sample',\n",
    "    columns=6\n",
    ").resolve_scale(\n",
    "    y='independent',\n",
    "    x='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'x': range(9),\n",
    "    'y': [1, 2, 3, 4, 5, 4, 3, 2, 1]\n",
    "})\n",
    "\n",
    "brush = alt.selection_interval(name=\"brush\", encodings=['x'])\n",
    "alt.Chart(data).mark_line().add_selection(brush).transform_calculate(\n",
    "    scaled_by_brush_width='datum.y * (isDefined(brush.x) ? (brush.x[1] - brush.x[0]) : 1)'\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    y='scaled_by_brush_width:Q'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPSchleiSediments-bSFBF4Xj",
   "language": "python",
   "name": "mpschleisediments-bsfbf4xj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
