{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist\n",
    "from rasterio.mask import mask\n",
    "import json\n",
    "import pandas as pd\n",
    "import hvplot.pandas  # noqa\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "try:  # if on phy-server local modules will not be found if their directory is not added to PATH\n",
    "    import sys\n",
    "    sys.path.append(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "    import os\n",
    "    os.chdir(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from settings import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% loading data\n"
    }
   },
   "outputs": [],
   "source": [
    "# # What happened so far: DB extract and blank procedure. Now import resulting MP data from csv\n",
    "# mp_pdd = prepare_data.get_pdd()\n",
    "\n",
    "# # Also import sediment data (sediment frequencies per size bin from master sizer export)\n",
    "# grainsize_iow, grainsize_cau, sed_lower_boundaries = prepare_data.get_grainsizes()\n",
    "\n",
    "# # ...some data wrangling to prepare particle domain data and sample domain data for MP and combine with certain sediment aggregates.\n",
    "# mp_sdd = prepare_data.aggregate_SDD(mp_pdd)\n",
    "# sdd_iow = prepare_data.additional_sdd_merging(mp_sdd)\n",
    "# sdd_cau = pd.read_csv('../data/Metadata_CAU_sampling_log.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create geodataframe from geojson file\n",
    "poly = gpd.read_file('../data/SchleiCoastline_from_OSM.geojson')\n",
    "poly_as_str = [json.loads(poly.to_json())['features'][0]['geometry']]\n",
    "# poly.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savestamp = '20230403_233901'\n",
    "f = [c for c in Path('../data/exports/models/predictions').glob(f'{savestamp}*.csv')][0]\n",
    "target = f.name.split('_')[-2]\n",
    "station_data = pd.read_csv(f)\n",
    "station_data = gpd.GeoDataFrame(station_data, geometry=gpd.points_from_xy(station_data.LON, station_data.LAT), crs='EPSG:4326')\n",
    "station_data\n",
    "## old mehod\n",
    "# station_data = gpd.GeoDataFrame(sdd_iow, geometry=gpd.points_from_xy(sdd_iow['LON'], sdd_iow['LAT'], crs='EPSG:4326')).to_crs(\"EPSG:3857\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.to_crs(Config.baw_epsg, inplace=True)\n",
    "poly.to_crs(Config.baw_epsg, inplace=True)\n",
    "\n",
    "xres = yres = Config.interpolation_resolution\n",
    "xmin, ymin, xmax, ymax = poly.total_bounds\n",
    "xgrid, ygrid = np.meshgrid(np.arange(xmin, xmax + xres, xres), \n",
    "                           np.arange(ymin, ymax + yres, yres),\n",
    "                          )\n",
    "\n",
    "points = np.vstack((station_data.geometry.x, station_data.geometry.y)).T\n",
    "\n",
    "values = griddata(\n",
    "    points, station_data[target],\n",
    "    (xgrid, ygrid),\n",
    "    method=Config.interpolation_method,  # 'linear' and 'cubic' will result in nan outside of the convex hull of data points\n",
    ")\n",
    "\n",
    "nan_mask = np.isnan(values)  # if there are any nan points re-interpolate them using method 'nearest'\n",
    "\n",
    "if np.any(nan_mask):\n",
    "    values2 = griddata(\n",
    "        points, station_data[target],\n",
    "        (xgrid, ygrid), method='nearest',\n",
    "    )\n",
    "    # values[nan_mask] = values2[nan_mask]\n",
    "\n",
    "grid_gdf = gpd.GeoDataFrame({f'{target}': values.ravel()}, \n",
    "                            geometry=gpd.points_from_xy(xgrid.ravel(), ygrid.ravel()),\n",
    "                            crs=Config.baw_epsg,\n",
    "                            )\n",
    "clipped = grid_gdf.clip(poly)\n",
    "## old method:\n",
    "# clipped = gpd.overlay(grid_gdf, poly, how='intersection')  # takes about 15 min\n",
    "# clipped = clipped.loc[grid_gdf.intersects(poly.geometry[0])]  # takes about 11 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipped.plot(column=target, cmap='OrRd', edgecolor=\"none\", antialiased=False)\n",
    "# alt.Chart(clipped.assign(X = clipped.geometry.x, Y = clipped.geometry.y)).mark_square(size=100).encode(\n",
    "#     x='X',\n",
    "#     y='Y',\n",
    "#     color=target\n",
    "# ).interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_areas = xres * yres\n",
    "total = (clipped[target] * cell_areas).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total / poly.area / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(values, bounds=(xmin, ymin, xmax, ymax)).opts(width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(values, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f'../data/exports/models/predictions/{savestamp}_raster.tif'\n",
    "\n",
    "transform = from_origin(xmin, ymax, Config.interpolation_resolution, Config.interpolation_resolution)\n",
    "\n",
    "new_dataset = rasterio.open(f, 'w', driver='GTiff',\n",
    "                            height = values.shape[0], width = values.shape[1],\n",
    "                            count=1, dtype=str(values.dtype),\n",
    "                            crs=Config.baw_epsg,\n",
    "                            transform=transform)\n",
    "new_dataset.write(values, 1)\n",
    "new_dataset.close()\n",
    "rasta = rasterio.open(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img, out_transform = mask(rasta, poly_as_str, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show((out_img, 1), cmap='terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPSchleiSediments-VkVOo8Jb",
   "language": "python",
   "name": "mpschleisediments-vkvoo8jb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "82a31816b63c673b7463547b8d8376fc489f1e362f1a21f244a13819d6095661"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
