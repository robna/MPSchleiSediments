{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db100ade-bde7-43ad-b2ae-cdb605cbcb64",
   "metadata": {},
   "source": [
    "## Notebook for demonstration of GPBoost library.\n",
    "\n",
    "Constructed after the example at: https://towardsdatascience.com/tree-boosting-for-spatial-data-789145d6d97d\n",
    "\n",
    "Github: https://github.com/fabsig/GPBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dc8d640-1f1d-43db-8d47-c4620c26a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpboost as gpb\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b1bf7b-c7c1-41d0-b81b-2eda95132cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "# Simulate Gaussian process: training and test data (the latter on a grid for visualization)\n",
    "sigma2_1 = 0.35  # marginal variance of GP\n",
    "rho = 0.1  # range parameter\n",
    "sigma2 = 0.1  # error variance\n",
    "n = 200  # number of training samples\n",
    "nx = 50 # test data: number of grid points on each axis\n",
    "# training locations (exclude upper right rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fb03f8-1b54-4f0d-bc9e-b5ca7aa8442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.column_stack(\n",
    "  (np.random.uniform(size=1)/2, np.random.uniform(size=1)/2))\n",
    "while coords.shape[0] < n:\n",
    "    coord_i = np.random.uniform(size=2)\n",
    "    if not (coord_i[0] >= 0.6 and coord_i[1] >= 0.6):\n",
    "        coords = np.vstack((coords,coord_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c61984d-e69a-425a-bd7f-b59b3f435b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test locations (rectangular grid)\n",
    "s_1 = np.ones(nx * nx)\n",
    "s_2 = np.ones(nx * nx)\n",
    "for i in range(nx):\n",
    "    for j in range(nx):\n",
    "        s_1[j * nx + i] = (i + 1) / nx\n",
    "        s_2[i * nx + j] = (i + 1) / nx\n",
    "coords_test = np.column_stack((s_1, s_2))\n",
    "n_all = nx**2 + n # total number of data points \n",
    "coords_all = np.vstack((coords_test,coords))\n",
    "D = np.zeros((n_all, n_all))  # distance matrix\n",
    "for i in range(0, n_all):\n",
    "    for j in range(i + 1, n_all):\n",
    "        D[i, j] = np.linalg.norm(coords_all[i, :] - coords_all[j, :])\n",
    "        D[j, i] = D[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941f4ec8-711e-4864-8eb6-336e8e3ab729",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = sigma2_1 * np.exp(-D / rho) + np.diag(np.zeros(n_all) + 1e-10)\n",
    "C = np.linalg.cholesky(Sigma)\n",
    "b_all = C.dot(np.random.normal(size=n_all))\n",
    "b_train = b_all[(nx*nx):n_all] # training data GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77a0b7b-a65f-488f-9d1a-0155a2034b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean function. Use two predictor variables of which only one has an effect for easy visualization\n",
    "def f1d(x):\n",
    "    return np.sin(3*np.pi*x) + (1 + 3 * np.maximum(np.zeros(len(x)),x-0.5)/(x-0.5)) - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a84232-e13b-4949-9fe9-2053ef826a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(n, 2)\n",
    "F_X_train = f1d(X[:, 0]) # mean\n",
    "xi_train = np.sqrt(sigma2) * np.random.normal(size=n)  # simulate error term\n",
    "y = F_X_train + b_train + xi_train  # observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd551379-07ad-4cb1-af68-2f64674ee597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "x = np.linspace(0,1,nx**2)\n",
    "x[x==0.5] = 0.5 + 1e-10\n",
    "X_test = np.column_stack((x,np.zeros(nx**2)))\n",
    "F_X_test = f1d(X_test[:, 0])\n",
    "b_test = b_all[0:(nx**2)]\n",
    "xi_test = np.sqrt(sigma2) * np.random.normal(size=(nx**2))\n",
    "y_test = F_X_test + b_test + xi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f417a3b-85dd-4626-847f-5d17934a347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model = gpb.GPModel(gp_coords=coords, cov_function=\"exponential\")\n",
    "data_train = gpb.Dataset(X, y)\n",
    "params = { 'objective': 'regression_l2', 'learning_rate': 0.01,\n",
    "            'max_depth': 3, 'min_data_in_leaf': 10, \n",
    "            'num_leaves': 2**10, 'verbose': 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86ec2da6-e960-46c7-859a-e372fc7b3bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance parameters \n",
      "['Error_term', 'GP_var', 'GP_range']\n",
      "[0.00311149 0.28957122 0.0586757 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gpboost.basic.GPModel at 0x7ff71a78c670>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "bst = gpb.train(params=params, train_set=data_train,\n",
    "                gp_model=gp_model, num_boost_round=247)\n",
    "gp_model.summary() # Estimated covariance parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dab18135-bad2-4a7b-9a02-c9dd63d16333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred = bst.predict(data=X_test, gp_coords_pred=coords_test,\n",
    "                    predict_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "769ea0b3-47ca-46f6-9d15-a6214a549495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the predictions of the trees and the GP\n",
    "y_pred = pred['fixed_effect'] + pred['random_effect_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feced773-9993-44db-9afc-ae9d692e12fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model interpretation\n",
    "shap_values = shap.TreeExplainer(bst).shap_values(X)\n",
    "shap.summary_plot(shap_values, X)\n",
    "shap.dependence_plot(\"Feature 0\", shap_values, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPSchleiSediments-bSFBF4Xj",
   "language": "python",
   "name": "mpschleisediments-bsfbf4xj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
