{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676bdbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "import altair_transform\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be04c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import quality checked and blank substracted list of MP from Micropoll_SchleiSediment_blank_subtract.ipynb\n",
    "env_MP = pd.read_csv('env_MP_clean_list_SchleiSediments.csv',index_col=0)\n",
    "#rename column name of Size_1\n",
    "env_MP.rename(columns = {'Size_1_[µm]':'Size_1_µm'}, inplace = True)\n",
    "#env_MP_a500 = env_MP.loc[env_MP.size_geom_mean >= 500]\n",
    "#env_MP_b500 = env_MP.loc[env_MP.size_geom_mean < 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698e958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groupy_env_MP = env_MP.groupby(['Sample'])\n",
    "\n",
    "mp_station = groupy_env_MP.agg(\n",
    "        Frequency=('Site_name', 'count'),  # using 'Site_name' here for count, could use any other column too... Is there a way to count entries in groups without using a column?\n",
    "        FrequencyA500=('size_geom_mean', lambda x: (x>=500).sum()),  # using 'Site_name' here for count, could use any other column too... Is there a way to count entries in groups without using a column?\n",
    "        FrequencyB500=('size_geom_mean', lambda x: (x<500).sum()),  # using 'Site_name' here for count, could use any other column too... Is there a way to count entries in groups without using a column?\n",
    "        Mass=('Sampling_weight_[kg]', np.mean),  # using \"mean\" here is actually weird as all entries are the same. Is there something like \"first\"?\n",
    "        GPS_LONs = ('GPS_LON', np.mean),\n",
    "        GPS_LATs = ('GPS_LAT', np.mean),\n",
    "        Split = ('Fraction_analysed', np.mean),\n",
    "        MP_D50 = ('size_geom_mean',np.median)\n",
    "        ##MP_D50_A500 = ('size_geom_mean' >= 500.median()),\n",
    "        #MP_D50_B500 = ('size_geom_mean', lambda x: (x<500).median())\n",
    " ).reset_index()\n",
    "\n",
    "mp_station['Concentration'] =  round(mp_station['Frequency']/ (mp_station['Mass'] * mp_station['Split']))\n",
    "mp_station['ConcentrationA500'] =  round(mp_station['FrequencyA500']/ (mp_station['Mass'] * mp_station['Split']))\n",
    "mp_station['ConcentrationB500'] =  round(mp_station['FrequencyB500']/ (mp_station['Mass'] * mp_station['Split']))\n",
    "mp_station.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e58473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import d50 values \n",
    "sed_d50 = pd.read_csv('Schlei_Sed_D50_new.csv',index_col=0)\n",
    "sed_63 = pd.read_csv('Schlei_Sed_D50_new.csv',index_col=0)\n",
    "\n",
    "#import ogranic matter size, TOC, Hg data\n",
    "sed_OM = pd.read_csv('Schlei_OM.csv',index_col=0)\n",
    "\n",
    "#import sampling log data\n",
    "slogs= pd.read_csv('Schlei_sed_sampling_log.csv',index_col=0)\n",
    "\n",
    "Dist_WWTP = pd.read_csv('Schlei_Sed_Dist_WWTP.csv',index_col=0)\n",
    "\n",
    "#merge with mp per station\n",
    "mp_sedStats = pd.merge(mp_station,slogs.reset_index(),on=['Sample'], how='left')\n",
    "mp_sedStats = pd.merge(mp_sedStats,sed_d50.reset_index(),on=['Sample'], how='left')\n",
    "mp_sedStats = pd.merge(mp_sedStats,sed_OM.reset_index(),on=['Sample'], how='left')\n",
    "mp_sedStats = pd.merge(mp_sedStats,Dist_WWTP.reset_index(),on=['Sample'], how='left')\n",
    "\n",
    "mp_sedStats.to_csv('MP_Stats_SchleiSediments.csv')\n",
    "mp_sedStats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c5ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary\n",
    "Regio_Sep =  {'Schlei_S1_15cm': 'inner',\n",
    "              'Schlei_S2': 'inner',\n",
    "              'Schlei_S3': 'inner',\n",
    "              'Schlei_S5': 'river',\n",
    "              'Schlei_S8': 'inner',\n",
    "              'Schlei_S10': 'inner',\n",
    "              'Schlei_S10_15cm': 'inner',\n",
    "              'Schlei_S11': 'inner',\n",
    "              'Schlei_S13': 'inner',\n",
    "              'Schlei_S14': 'outlier',\n",
    "              'Schlei_S15': 'inner',\n",
    "              'Schlei_S17': 'inner',\n",
    "              'Schlei_S19': 'outlier',\n",
    "              'Schlei_S22': 'outer',\n",
    "              'Schlei_S23': 'outer',\n",
    "              'Schlei_S24': 'outer', \n",
    "              'Schlei_S25': 'outer',\n",
    "              'Schlei_S26': 'outer',\n",
    "              'Schlei_S27': 'outer', \n",
    "              'Schlei_S30': 'outer', \n",
    "              'Schlei_S31': 'outer'}\n",
    "\n",
    "mp_sedStats = mp_sedStats.merge(pd.DataFrame.from_dict(Regio_Sep,orient='index',columns=['Regio_Sep']),left_on='Sample',right_index=True)\n",
    "#mp_sedStats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_MP = env_MP.merge(mp_sedStats[['Sample', 'TOC', 'Regio_Sep']], on='Sample')\n",
    "env_MP.rename(columns={'TOC': 'TOCs', 'Sampling_weight_[kg]': 'Sampling_weight'}, inplace=True)\n",
    "env_MP.drop(['Site_name', 'GPS_LON', 'GPS_LAT', 'Compartment',\n",
    "                      'Contributor', 'Project', 'Size_1_µm', 'Size_2_[µm]', 'Shape', 'Colour',\n",
    "                      'polymer_type', 'library_entry', 'lab_blank_ID', 'sample_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_bandwidth(data, kernel, bandwidths=10**np.linspace(0,2,100)):\n",
    "    grid = GridSearchCV(KernelDensity(kernel='gaussian'),\n",
    "                        {'bandwidth': bandwidths},\n",
    "                        cv=LeaveOneOut())\n",
    "    grid.fit(data[:, None]);\n",
    "    bw = grid.best_params_['bandwidth']\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kde(data, x_d=np.linspace(0,999,1000), optimise_bw=True , kernel='gaussian'):  # data should be 1D np-array, x_d is the discrete values where the probability density is evaluated, bw is the bandwidth to be used for the kernels\n",
    "    \n",
    "    bw = optimise_bandwidth(data, kernel) if optimise_bw else 50\n",
    "    \n",
    "    # instantiate and fit the KDE model\n",
    "    kde = KernelDensity(bandwidth=bw, kernel=kernel)\n",
    "    kde.fit(data[:, None])\n",
    "    # score_samples returns the log of the probability density\n",
    "    logprob = kde.score_samples(x_d[:, None])\n",
    "    kde_result = np.exp(logprob)\n",
    "    \n",
    "    return kde_result, bw\n",
    "\n",
    "#plt.fill_between(x_d, kde_result, alpha=0.5)\n",
    "#plt.plot(x, np.full_like(x, -0.001), '|k', markeredgewidth=1)\n",
    "#plt.xlim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = env_MP.loc[env_MP.Sample == 'Schlei_S10', 'size_geom_mean'].values\n",
    "\n",
    "SampleGroups = env_MP.groupby(['Sample'])\n",
    "\n",
    "kde_results = pd.DataFrame({'x_d': np.linspace(0,999,1000)})\n",
    "\n",
    "for SampleName, SampleGroup in SampleGroups:\n",
    "    x = SampleGroup.size_geom_mean.values\n",
    "    kde_result, bw = calculate_kde(x, optimise_bw=False)\n",
    "    \n",
    "    kde_results[SampleName] = kde_result\n",
    "    \n",
    "    print(f'{SampleName}:    bandwidth is {round(bw,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(kde_results.melt(id_vars=['x_d'])).mark_line().encode(\n",
    "    x='x_d',\n",
    "    y='value',\n",
    "    color='variable',\n",
    "    tooltip='variable'\n",
    ").interactive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
