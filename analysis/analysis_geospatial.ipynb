{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.plot import show, show_hist\n",
    "from rasterio.mask import mask\n",
    "import json\n",
    "import pandas as pd\n",
    "import hvplot.pandas  # noqa\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "try:  # if on phy-server local modules will not be found if their directory is not added to PATH\n",
    "    import sys\n",
    "    sys.path.append(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "    import os\n",
    "    os.chdir(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from settings import Config\n",
    "from prepare_data import patsy_transform\n",
    "from cv import performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create geodataframe from geojson file\n",
    "poly = gpd.read_file('../data/SchleiCoastline_from_OSM.geojson')\n",
    "# poly.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read predicted data from model run\n",
    "# savestamp = '20230403_233901'\n",
    "savestamp = '20230501_172522'\n",
    "f = [c for c in Path('../data/exports/models/predictions').glob(f'{savestamp}*.csv')][0]\n",
    "target = f.name.split('_')[-2]\n",
    "station_data = pd.read_csv(f)\n",
    "\n",
    "if target == 'Concentration':\n",
    "    for k, v in Config.massConc_from_numConc.items():\n",
    "        station_data[k] = patsy_transform(v, station_data)  # OBS: MassConc is in µg/kg. Divide by 1e9 to get MassConc in kg MP per kg dry sediment!\n",
    "\n",
    "station_data = gpd.GeoDataFrame(station_data, geometry=gpd.points_from_xy(station_data.LON, station_data.LAT), crs='EPSG:4326')\n",
    "# station_data.head(30)\n",
    "\n",
    "## old mehod\n",
    "# station_data = gpd.GeoDataFrame(sdd_iow, geometry=gpd.points_from_xy(sdd_iow['LON'], sdd_iow['LAT'], crs='EPSG:4326')).to_crs(\"EPSG:3857\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this cell to exclude outlier samples S05 and S32\n",
    "\n",
    "# station_data.loc[station_data.Sample=='S05', 'Concentration_observed'] = np.nan\n",
    "# station_data.loc[station_data.Sample=='S32', 'Concentration_observed'] = np.nan\n",
    "\n",
    "# station_data.loc[station_data.Sample=='S05', 'MassConcentration_observed'] = np.nan\n",
    "# station_data.loc[station_data.Sample=='S32', 'MassConcentration_observed'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the performance of the prediction against the seen trainings data\n",
    "performance(station_data.set_index('Sample').loc[~station_data.set_index('Sample')[f'{target}_observed'].isna(), f'{target}_observed'],\n",
    "            station_data.set_index('Sample').loc[~station_data.set_index('Sample')[f'{target}_observed'].isna(), f'{target}_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run perforance test for \"MassConcentration\", regressed from \"Concentration\"\n",
    "performance(station_data.set_index('Sample').loc[~station_data.set_index('Sample')[f'MassConcentration_observed'].isna(), f'MassConcentration_observed'],\n",
    "            station_data.set_index('Sample').loc[~station_data.set_index('Sample')[f'MassConcentration_observed'].isna(), f'MassConcentration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.to_crs(Config.baw_epsg, inplace=True)\n",
    "poly.to_crs(Config.baw_epsg, inplace=True)\n",
    "poly_as_str = [json.loads(poly.to_json())['features'][0]['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_interp(data, name, xgrid, ygrid):\n",
    "    '''\n",
    "    Interpolates point data from geopandas geoseries to a numpy 2D-array of regularly spaced grid points.\n",
    "    '''\n",
    "\n",
    "    points = np.vstack((data.geometry.x, data.geometry.y)).T\n",
    "    values = griddata(\n",
    "        points, data[name],\n",
    "        (xgrid, ygrid),\n",
    "        method=Config.interpolation_method,  # 'linear' and 'cubic' will result in nan outside of the convex hull of data points\n",
    "    )\n",
    "    nan_mask = np.isnan(values)  # if there are any nan points re-interpolate them using method 'nearest'\n",
    "\n",
    "    if np.any(nan_mask):\n",
    "        values2 = griddata(\n",
    "            points, data[name],\n",
    "            (xgrid, ygrid), method='nearest',\n",
    "        )\n",
    "        values[nan_mask] = values2[nan_mask]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_clip(values, poly, xgrid, ygrid):\n",
    "    '''\n",
    "    Clips raster layers (ndarray), by converting into geodataframe, using clip and extracting the \n",
    "    '''\n",
    "    grid_gdf = gpd.GeoDataFrame({'vals': values.ravel()}, \n",
    "                                geometry=gpd.points_from_xy(xgrid.ravel(), ygrid.ravel()),\n",
    "                                crs=Config.baw_epsg,\n",
    "                                )\n",
    "    clipper = grid_gdf.clip(poly)\n",
    "    ## old method:\n",
    "    # clipper = gpd.overlay(grid_gdf, poly, how='intersection')  # takes about 15 min\n",
    "    # clipper = clipper.loc[grid_gdf.intersects(poly.geometry[0])]  # takes about 11 min\n",
    "\n",
    "    grid_gdf.loc[~grid_gdf.index.isin(clipper.index), 'vals'] = np.nan\n",
    "    return grid_gdf['vals'].values.reshape(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xres = yres = Config.interpolation_resolution\n",
    "xmin, ymin, xmax, ymax = poly.total_bounds\n",
    "xgrid, ygrid = np.meshgrid(np.arange(xmin, xmax + xres, xres), \n",
    "                           np.arange(ymin, ymax + yres, yres),\n",
    "                          )\n",
    "\n",
    "# target_values = grid_interp(station_data, target, xgrid, ygrid)\n",
    "target_values = grid_interp(station_data, 'MassConcentration', xgrid, ygrid)\n",
    "sedDBD_values = grid_interp(station_data, 'SedDryBulkDensity', xgrid, ygrid)\n",
    "\n",
    "target_clipped = grid_clip(target_values, poly, xgrid, ygrid)\n",
    "sDBD_clipped = grid_clip(sedDBD_values, poly, xgrid, ygrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # src_filename = '/home/rob/ownCloud/microSCHLEI/Sediment_K/predictions/whitebox_IDWinterp_MinNum2_weight1_radius200.tif'\n",
    "# # src_filename = '/home/rob/ownCloud/microSCHLEI/Sediment_K/predictions/final_interpolations/MP_conc_woproxy_idwwb_interpolated_clipped.tif'\n",
    "# src_filename = '/home/rob/ownCloud/microSCHLEI/Sediment_K/predictions/final_interpolations/interpolated_sibson_clipped.tif'\n",
    "# with rio.open(src_filename, \"r\") as src:\n",
    "#        target_clipped = src.read(1)\n",
    "# target_clipped[target_clipped==src.nodata] = np.nan\n",
    "# src.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipped.plot(column=target, cmap='OrRd', edgecolor=\"none\", antialiased=False)\n",
    "# alt.Chart(clipped.assign(X = clipped.geometry.x, Y = clipped.geometry.y)).mark_square(size=100).encode(\n",
    "#     x='X',\n",
    "#     y='Y',\n",
    "#     color=target\n",
    "# ).interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_area = xres * yres  # grid cell are in m² from cell width * cell height in m\n",
    "cell_sedVol = cell_area * Config.sediment_layer_depth  # volume of sediment layer considered in m³\n",
    "sedMass_grid = np.nan_to_num(sDBD_clipped) * cell_sedVol  # mass of sediment in each cell, calculated from (interpolated) sediment dry bulk density (kg m⁻³) * volume of sediment per cell (m³)\n",
    "abundance_grid = np.nan_to_num(target_clipped) * sedMass_grid  # grid of target amounts (MP particles if target==Conentration; MP mass if target==MassConcentration)\n",
    "total = abundance_grid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total MP in upper {Config.sediment_layer_depth*100} cm of Schlei sediments: {np.round(total / 1e12, 1)} Trillion')\n",
    "print(f'MP per m² and cm sediment depth: {round(total / poly.area[0] / (Config.sediment_layer_depth * 100))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total / sedMass_grid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(target_clipped).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv.help(hv.Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds=(xmin, ymin, xmax, ymax)   # Coordinate system: (left, bottom, right, top)\n",
    "hv.Image(target_clipped, bounds=bounds).opts(cmap='RdYlBu_r', cnorm='log', clim=(40,40000), width=int(target_values.shape[1]/5), height=int(target_values.shape[0]/5), invert_yaxis=True)#, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(sDBD_clipped, origin='lower', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f'../data/exports/models/predictions/{savestamp}_raster.tif'\n",
    "\n",
    "transform = from_origin(xmin, ymax, Config.interpolation_resolution, Config.interpolation_resolution)\n",
    "\n",
    "new_dataset = rio.open(f, 'w', driver='GTiff',\n",
    "                            height = target_values.shape[0], width = target_values.shape[1],\n",
    "                            count=1, dtype=str(target_values.dtype),\n",
    "                            crs=Config.baw_epsg,\n",
    "                            transform=transform)\n",
    "new_dataset.write(target_values, 1)\n",
    "new_dataset.close()\n",
    "rasta = rio.open(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img, out_transform = mask(rasta, poly_as_str, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show((out_img, 1), cmap='terrain')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
