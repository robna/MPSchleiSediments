{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import hvplot.pandas  # noqa\n",
    "pd.options.plotting.backend = 'holoviews'\n",
    "import altair as alt\n",
    "import altair_transform\n",
    "from scipy import stats\n",
    "\n",
    "try:  # if on phy-server local modules will not be found if their directory is not added to PATH\n",
    "    import sys\n",
    "    sys.path.append(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "    import os\n",
    "    os.chdir(\"/silod7/lenz/MPSchleiSediments/analysis/\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import prepare_data\n",
    "from dists import compose_dists_df\n",
    "import outliers\n",
    "import KDE_utils\n",
    "import correlations\n",
    "from components import PCA, PCOA\n",
    "import plots\n",
    "import glm\n",
    "from settings import Config\n",
    "\n",
    "# alt.renderers.enable('altair_viewer')  # use to display altair charts externally in bgser instead of inline (only activate in non-vega-compatible IDE like pycharm)\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and prepare data\n",
    "**Before running, check the computational parameters in settings.py**\n",
    "\n",
    "Nomenclature:\n",
    "- *pdd*: particle domain data = data is particle based, meaning one entry (row) corresponds to one particle and one feature (column) corresponds to one property observed for that particle\n",
    "- *sdd*: sample domain data = data is sample based, meaning one entry (row) corresponds to one sample and one feature (column) corresponds to one property observed for that sample\n",
    "- *mp*: data on microplastics\n",
    "- *sed*: data on sediments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% loading data\n"
    }
   },
   "outputs": [],
   "source": [
    "# What happened so far: DB extract and blank procedure. Now import resulting MP data from csv\n",
    "mp_pdd = prepare_data.get_pdd()\n",
    "\n",
    "# Also import sediment data (sediment frequencies per size bin from master sizer export)\n",
    "grainsize_iow, grainsize_cau, sed_lower_boundaries = prepare_data.get_grainsizes()\n",
    "\n",
    "# ...some data wrangling to prepare particle domain data and sample domain data for MP and combine with certain sediment aggregates.\n",
    "mp_sdd = prepare_data.aggregate_SDD(mp_pdd)\n",
    "sdd_iow = prepare_data.additional_sdd_merging(mp_sdd)\n",
    "sdd_cau = pd.read_csv('../data/Metadata_CAU_sampling_log.csv', index_col=0).join(pd.read_csv('../data/GRADISTAT_CAU_vol_log-cau_closed.csv', index_col=0), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scatter plot of MP against Sediment-proxy with multi-regression grouped by region\n",
    "#x=  'D50 (µm)'\n",
    "#x= 'TOC'\n",
    "x = 'perc MUD'\n",
    "y= 'Concentration'\n",
    "\n",
    "plot, plot_params = plots.scatter_chart(\n",
    "    sdd_iow, x, y,\n",
    "    color='regio_sep',\n",
    "    reg='linear',\n",
    "    reg_groups=True,\n",
    "    ytransform=True\n",
    "    )\n",
    "print(plot_params)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(sdd_iow,\n",
    "                 x=\"perc MUD\",\n",
    "                 y=\"Concentration\",\n",
    "                 color=\"regio_sep\",\n",
    "                 #log_y=True, \n",
    "                 trendline=\"ols\",\n",
    "                 #trendline_options=dict(log_y=True)\n",
    "                )\n",
    "fig.show()\n",
    "results = px.get_trendline_results(fig)\n",
    "results.query(\"regio_sep == 'warnow'\").px_fit_results.iloc[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdd_iow['pred_ConcentrationA500'] = np.exp(0.505 + 0.0452 * sdd_iow['perc MUD'] + 0.0249 * 2.22 * sdd_iow['TOC'])\n",
    "# alt.Chart(sdd_iow).mark_point().encode(x='ConcentrationA500',y='pred_ConcentrationA500',tooltip='Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate distributions (contour plots) of MP / SED / OM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_particles = compose_dists_df(n=len(mp_pdd), plot_bins=100)  # create theoretical distributions for all particle types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conMP = pd.DataFrame({  # add observd MP data\n",
    "    'particle_type': ['MPobs'] * len(mp_pdd),\n",
    "    'density': mp_pdd['density'],\n",
    "    'size': mp_pdd['size_geom_mean'],\n",
    "    'longevity': contour_particles.loc[contour_particles['particle_type']=='MP', 'longevity'].values\n",
    "    })\n",
    "contour_particles = pd.concat([contour_particles,conMP]).reset_index(drop=True)\n",
    "\n",
    "## Optional block: take log values of data before plotting\n",
    "contour_particles['log_size'] = np.log10(contour_particles['size'])\n",
    "contour_particles['log_longevity'] = np.log10(contour_particles['longevity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_particles.loc[contour_particles.particle_type=='SED'].hvplot.bivariate('density', 'size', logy=True, clabel='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_particles.hvplot.kde('size', by='particle_type', xlim=(1, 1000), width=300, subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.sns_contour_plot(\n",
    "    contour_particles,\n",
    "    'density',\n",
    "    'size',\n",
    "    'particle_type',\n",
    "    xlim=(7*10**2, 3*10**3),\n",
    "    ylim=(-200, 2300),\n",
    "    log=(False, False),\n",
    "    figsize=(10,10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.density_contour(\n",
    "    contour_particles,\n",
    "    x='density',\n",
    "    y='size',\n",
    "    color='particle_type',\n",
    "    color_discrete_sequence=px.colors.qualitative.D3,\n",
    "    # marginal_x='histogram',\n",
    "    # marginal_y='histogram',\n",
    "    range_y=[1,2500],\n",
    "    width=800,\n",
    "    height=800)\n",
    "\n",
    "# fig.update_traces(marker_line_width=0.5)\n",
    "\n",
    "# fig.add_scatter(\n",
    "#     x=contour_particles['density'],\n",
    "#     y=contour_particles['log [size (µm)]'],\n",
    "#     mode='markers',\n",
    "#     marker=dict(size=1),\n",
    "#     )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plotly_contour_plot(x=contour_particles['density'],y=contour_particles['log [size (µm)]'], nbins=100, ncontours=10, figsize=(800, 600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymer composition analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = prepare_data.aggregate_SDD(mp_pdd.groupby(['Sample', 'polymer_type'])).merge(sdd_iow[['Sample', 'Dist_WWTP', 'regio_sep']], on='Sample')\n",
    "# comp['polymer_type'] = comp.Shape\n",
    "\n",
    "com = comp.pivot(index=['Sample'], columns=['polymer_type'], values=['Concentration']).droplevel(0,axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scor, load, expl = PCOA(com, 2)  # call either PCA or PCOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pc_plot = plots.biplot(scor, load, expl, sdd_iow, 'PC1', 'PC2', sc='regio_sep', lc='polymer_type', ntf=7, normalise=True)\n",
    "pc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com2 = comp.pivot(\n",
    "    index=['Sample', 'regio_sep'],\n",
    "    columns=['polymer_type'],\n",
    "    values=['Concentration']\n",
    "    ).droplevel(\n",
    "        0,\n",
    "        axis=1\n",
    "    ).fillna(0\n",
    "    ).reset_index(\n",
    "        level=1\n",
    "    ).melt(\n",
    "        id_vars=['regio_sep'],\n",
    "        value_name='Concentration',\n",
    "        ignore_index=False\n",
    "    ).groupby(\n",
    "        ['regio_sep', 'polymer_type']\n",
    "    ).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dropdown = alt.binding_select(options=list(com2['regio_sep'].unique()), name='select region ')\n",
    "selection = alt.selection_single(fields=['regio_sep'],\n",
    "                                 bind=input_dropdown,\n",
    "                                 init={'regio_sep': 'WWTP'})\n",
    "\n",
    "base = alt.Chart(com2).encode(\n",
    "    theta=alt.Theta('Concentration', stack=True),\n",
    "    color=alt.Color('ranked_polymer_type:N'),\n",
    "    tooltip=['regio_sep', 'polymer_type', 'PercentOfTotal:N']\n",
    ").transform_window(\n",
    "    rank='row_number()',\n",
    "    sort=[alt.SortField(\"Concentration\", order=\"descending\")],\n",
    ").transform_calculate(\n",
    "    ranked_polymer_type=\"datum.rank < 6 ? datum.polymer_type : ''\"\n",
    ").transform_joinaggregate(\n",
    "    total='sum(Concentration)',\n",
    "    groupby=['regio_sep']\n",
    ").transform_calculate(\n",
    "    PercentOfTotal=\"datum.Concentration / datum.total\"\n",
    ")\n",
    "\n",
    "pie = base.mark_arc(outerRadius=120, innerRadius=70, padAngle=0.01, cornerRadius=4)\n",
    "text = base.mark_text(radius=150, size=20).encode(text=\"ranked_polymer_type:N\")\n",
    "text2 = base.mark_text(radius=50, size=16).encode(text=alt.Text(\"PercentOfTotal:N\", format='.0%'))\n",
    "text3 = base.mark_text(radius=0, size=20).encode(text='regio_sep', color=alt.value('#000000'))\n",
    "\n",
    "alt.layer(\n",
    "    pie, text, text2, text3\n",
    ").add_selection(\n",
    "    selection\n",
    ").transform_filter(\n",
    "    selection\n",
    "# ).facet(column='regio_sep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = 'sphinx_gallery'\n",
    "# fig = px.scatter(scor.rename_axis(index='Sample').reset_index().merge(comp[['Sample', 'Dist_WWTP', 'regio_sep']], on='Sample'),\n",
    "#                     x='PC1',\n",
    "#                     y='PC2',\n",
    "#                     #z='PC3',  # when uncommenting: use px.scatter_3d instead of px.scatter\n",
    "#                     color='Dist_WWTP',\n",
    "#                     color_continuous_scale='Greys',\n",
    "#                     hover_name=\"Sample\")\n",
    "\n",
    "# # resize markers\n",
    "# fig.update_traces(marker=dict(size=10,\n",
    "#                               line=dict(width=2,\n",
    "#                                         color='DarkSlateGrey')),\n",
    "#                   selector=dict(mode='markers'))\n",
    "\n",
    "# # change size and move colorbar\n",
    "# fig.update_layout(autosize=False, width=1000, height=800,\n",
    "#                   coloraxis_colorbar=dict(yanchor=\"top\", y=1, x=0, ticks=\"outside\"))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## MP particle size distributions\n",
    "\n",
    "*This calculates probability density distributions for MP sizes. These are used to estimate the abundances of MP of specific size ranges, which can then be investigated for correlations to environmental parameters such as TOC or sediment grain size properties.*\n",
    "**Before running, check the computational parameters in settings.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% calculating probability densities\n"
    }
   },
   "outputs": [],
   "source": [
    "# KDEs for probability of finding a MP particle in a specific size bin are calculated.\n",
    "size_pdfs = KDE_utils.per_sample_kde(mp_pdd, sed_lower_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MP concentrations for each single-step size bin\n",
    "mp_size_conc = KDE_utils.probDens2conc(size_pdfs, mp_sdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MP and sediment abundances per size bin are equalised (only samples and bins contained in both of the are kept).\n",
    "# They are then melted and merged into MPsedMelted.\n",
    "mp_size_conc, grainsize_iow, mp_sed_melt = prepare_data.equalise_mp_and_sed(mp_size_conc, grainsize_iow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property-property-plot of MP%-per-size-bin against SED%-per-size-bin. Colors indicate the lower bouandary of each bin in µm.\n",
    "\n",
    "maxX = mp_sed_melt['SED'].max()\n",
    "maxY = mp_sed_melt['MP'].max()\n",
    "domain_max = max(maxX, maxY)\n",
    "\n",
    "input_dropdown = alt.binding_select(options=list(mp_sed_melt['Sample'].unique()), name='select sample ')\n",
    "selection = alt.selection_single(fields=['Sample'],\n",
    "                                 bind=input_dropdown,\n",
    "                                 init={'Sample': 'Schlei_S8'})\n",
    "\n",
    "identityLine = alt.Chart(mp_sed_melt).mark_line(\n",
    "    color= 'black',\n",
    "    # strokeDash=[3,8],\n",
    "    strokeWidth=0.4,\n",
    "    clip=True\n",
    ").encode(\n",
    "    x=alt.X('SED', axis=alt.Axis(title=''), scale=alt.Scale(domain=[0, domain_max])),\n",
    "    y=alt.Y('SED', axis=alt.Axis(title=''), scale=alt.Scale(domain=[0, domain_max]))\n",
    ").transform_filter(selection).interactive()\n",
    "\n",
    "line = alt.Chart(mp_sed_melt).mark_line(strokeWidth=0.4).encode(\n",
    "    x='SED',\n",
    "    y='MP',\n",
    "    order='lower'\n",
    ").transform_filter(selection).interactive()\n",
    "\n",
    "dots = alt.Chart(mp_sed_melt).mark_circle(\n",
    "    size=100\n",
    ").encode(\n",
    "    x='SED',\n",
    "    y='MP',\n",
    "    color=alt.Color('lower', scale=alt.Scale(scheme='turbo')),\n",
    "    tooltip=['MP', 'SED', 'lower', 'upper']\n",
    ").add_selection(selection\n",
    ").transform_filter(selection).interactive()\n",
    "\n",
    "proproplot = alt.layer(\n",
    "    identityLine, line, dots\n",
    "# ).configure_legend(\n",
    "#     gradientLength=600,\n",
    "#     gradientThickness=30\n",
    "# ).properties(width=600, height=600\n",
    ")\n",
    "\n",
    "MP_hist = alt.Chart(mp_pdd).mark_bar(opacity=0.4).encode(\n",
    "    x=alt.X('size_geom_mean', bin=alt.Bin(maxbins=1000), scale=alt.Scale(domain=[1, 2000])),\n",
    "    y=alt.Y('sum(pct):Q')\n",
    ").transform_joinaggregate(\n",
    "    total = 'count(*)',\n",
    "    groupby=['Sample']\n",
    ").transform_calculate(\n",
    "    pct='1 / datum.total'\n",
    ").transform_filter(selection)\n",
    "\n",
    "SED_hist = alt.Chart(mp_sed_melt).mark_bar(opacity=0.2, color='orange').encode(\n",
    "    x=alt.X('lower', bin=alt.Bin(maxbins=100), scale=alt.Scale(domain=[1, 2000])),\n",
    "    y=alt.Y('SED')\n",
    ").transform_filter(selection)\n",
    "\n",
    "\n",
    "MP = alt.Chart(mp_sed_melt.melt(id_vars=['Sample','lower','upper'], var_name='particle_type')).mark_line().encode(\n",
    "    x=alt.X('lower', scale=alt.Scale(domain=[1, 2000])),\n",
    "    y='value',\n",
    "    color=alt.Color('particle_type'),\n",
    ").transform_filter(selection)\n",
    "\n",
    "alt.hconcat(\n",
    "    proproplot, alt.layer(SED_hist, MP_hist, MP).resolve_scale(y='independent')\n",
    ").configure_legend(\n",
    "    gradientLength=300,\n",
    "    gradientThickness=30\n",
    "# ).properties(width=600, height=600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sediment size bin dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "# SEDpc, SEDexp, SEDload = sed_pca(SEDext.T)\n",
    "# sedpc, sedexp, sedload = sed_pca(grainsize_iow)\n",
    "\n",
    "# To see a loadings plot use:\n",
    "# sedload_df = pd.DataFrame(sedload, columns=['PC1', 'PC2', 'PC3'], index = np.unique(np.concatenate(np.char.split(sed_size_freqs.index.values.astype(str), '_')).ravel().astype(int))[:-1]).T\n",
    "# sedload_df.T.plot()  # x-axis corresponds to lower boundary of size bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCoA\n",
    "\n",
    "# sedpco = sed_pcoa(grainsize_iow, num_coords = 2)\n",
    "# sedpco = sed_pcoa(grainsize_iow.append(grainsize_cau), num_coords = 2)\n",
    "sedpco, sedloads, sedexpl = PCOA(grainsize_iow, num=2)\n",
    "\n",
    "# Plot PCo1 and PCo2\n",
    "# alt.Chart(sedpco.merge(sdd_iow, left_index=True, right_on='Sample').reset_index()).mark_point().encode(\n",
    "#     x='PC1',\n",
    "#     y='PC2',\n",
    "#     color='D50',\n",
    "#     tooltip='index'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set_theme(style=\"white\")\n",
    "\n",
    "# df = sedpco.merge(sdd_iow, left_index=True, right_on='Sample')\n",
    "# corrmat = df.corr()\n",
    "\n",
    "# # Generate a mask for the upper triangle\n",
    "# mask = np.triu(np.ones_like(corrmat, dtype=bool))\n",
    "\n",
    "# # Set up the matplotlib figure\n",
    "# f, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "# # Generate a custom diverging colormap\n",
    "# cmap = sns.diverging_palette(230, 10, as_cmap=True)\n",
    "\n",
    "# # Draw the heatmap with the mask and correct aspect ratio\n",
    "# sns.heatmap(corrmat, mask=mask, vmax=.3, center=0,\n",
    "#             square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alt.Chart(df).mark_circle().encode(\n",
    "#     alt.X(alt.repeat(\"column\"), type='quantitative'),\n",
    "#     alt.Y(alt.repeat(\"row\"), type='quantitative'),\n",
    "#     color='regio_sep:N',\n",
    "#     tooltip=['Sample']\n",
    "# ).properties(\n",
    "#     width=200,\n",
    "#     height=200\n",
    "# ).repeat(\n",
    "#     row=['D50', 'smaller63', 'MoM_ari_MEAN', 'MoM_ari_SORTING', 'MoM_ari_SKEWNESS', 'MoM_ari_KURTOSIS', 'MoM_geo_MEAN', 'MoM_geo_SORTING',\n",
    "#        'MoM_geo_SKEWNESS', 'MoM_geo_KURTOSIS', 'MoM_log_MEAN', 'MoM_log_SORTING', 'MoM_log_SKEWNESS', 'MoM_log_KURTOSIS',\n",
    "#        'FW_geo_MEAN', 'FW_geo_SORTING', 'FW_geo_SKEWNESS', 'FW_geo_KURTOSIS', 'FW_log_MEAN', 'FW_log_SORTING', 'FW_log_SKEWNESS', 'FW_log_KURTOSIS',\n",
    "#        'MODE 1 (µm)', 'MODE 2 (µm)', 'MODE 3 (µm)', 'D10 (µm)', 'D50 (µm)', 'D90 (µm)', '(D90 div D10) (µm)', '(D90 - D10) (µm)', '(D75 div D25) (µm)', '(D75 - D25) (µm)', 'perc GRAVEL', 'perc SAND', 'perc MUD',\n",
    "#        'perc V COARSE SAND', 'perc COARSE SAND', 'perc MEDIUM SAND', 'perc FINE SAND', 'perc V FINE SAND', 'perc V COARSE SILT', 'perc COARSE SILT',\n",
    "#        'perc MEDIUM SILT', 'perc FINE SILT', 'perc V FINE SILT', 'perc CLAY', 'Dx 50', 'TOC', 'Hg'],\n",
    "#     column=['PC1', 'PC2']\n",
    "# ).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a generalized linear model (GLM) to predict the microplastic concentration from the predictors\n",
    "\n",
    "glm_input = sdd_iow.merge(sedpco, left_on='Sample', right_index=True)\n",
    "\n",
    "glm_res = glm.glm(glm_input)\n",
    "print(glm_res.summary())\n",
    "# glm_res.predict(glm_input.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost model\n",
    "\n",
    "data = sdd_iow.merge(sedpco, left_on='Sample', right_index=True).set_index('Sample').copy()\n",
    "\n",
    "y = data.pop('Concentration') # Target vector in pd.Series format\n",
    "X = data.loc[:, ['MoM_ari_MEAN', 'MoM_ari_SORTING',\n",
    "       'MoM_ari_SKEWNESS', 'MoM_ari_KURTOSIS', 'MoM_geo_MEAN',\n",
    "       'MoM_geo_SORTING', 'MoM_geo_SKEWNESS', 'MoM_geo_KURTOSIS',\n",
    "       'MoM_log_MEAN', 'MoM_log_SORTING', 'MoM_log_SKEWNESS',\n",
    "       'MoM_log_KURTOSIS', 'perc GRAVEL', 'perc SAND',\n",
    "       'perc MUD', 'perc V COARSE SAND', 'perc COARSE SAND', 'perc MEDIUM SAND',\n",
    "       'perc FINE SAND', 'perc V FINE SAND', 'perc V COARSE SILT',\n",
    "       'perc COARSE SILT', 'perc MEDIUM SILT', 'perc FINE SILT',\n",
    "       'perc V FINE SILT', 'perc CLAY', 'OM_D50', 'TOC', 'Hg', 'Dist_WWTP',\n",
    "       'PC1', 'PC2']] # Feature matrix in pd.DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making train and test sets for both X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, shuffle=True)\n",
    "# Instantiate an XGBoost object with hyperparameters\n",
    "xgb_reg = xgb.XGBRegressor(col_sample=10, alpha=0.5, max_depth=2, n_estimators=1000, n_jobs=2,\n",
    "                           objective='reg:squarederror', booster='gbtree',\n",
    "                           random_state=42, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with train data sets\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_reg.predict(X_test) # Predictions\n",
    "y_true = y_test # True values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mse(y_true, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "R_squared = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\nRMSE: \", np.round(RMSE, 2))\n",
    "print()\n",
    "print(\"R-Squared: \", np.round(R_squared, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "from shapash.explainer.smart_explainer import SmartExplainer\n",
    "\n",
    "y_pred_as_series = pd.Series(y_pred, index=X_test.index, dtype=int)\n",
    "\n",
    "xpl = SmartExplainer() # Creating xpl object\n",
    "xpl.compile(x=X_test, model=xgb_reg, y_pred=y_pred_as_series)\n",
    "app = xpl.run_app() # Launch the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MP and sediment size range combination correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sum abundances in size bins for all possible combinations. Basically create all possible rebinnings and stack them into one DF\n",
    "# MPext = prepare_data.combination_sums(mp_size_conc.copy().T).T  # TODO: using transposed df's here, because combination_sums is not yet turned around: it takes features in rows and samples in columns...\n",
    "SEDext= prepare_data.combination_sums(grainsize_cau.copy().T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Altair size range correlation (PC~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pc='PC2'\n",
    "\n",
    "pc2gs_corr = pd.DataFrame(SEDext.corrwith(sedpco[pc], method='pearson'), columns=['pearson'])\n",
    "pc2gs_corr['spearman'] = SEDext.corrwith(sedpco[pc], method='spearman')\n",
    "pc2gs_corr['size_low'] = pc2gs_corr.index.str.split('_').str[0].astype(float)\n",
    "pc2gs_corr['size_up'] = pc2gs_corr.index.str.split('_').str[1].astype(float)\n",
    "pc2gs_corr['size_dif'] = pc2gs_corr['size_up'] - pc2gs_corr['size_low']\n",
    "\n",
    "df = sedpco.join(SEDext).melt(id_vars=['PC1','PC2'], ignore_index=False)\n",
    "df['size_low'] = df.variable.str.split('_').str[0].astype(float)\n",
    "df['size_up'] = df.variable.str.split('_').str[1].astype(float)\n",
    "df['size_dif'] = df['size_up'] - df['size_low']\n",
    "\n",
    "x_init = float(SEDext.iloc[:,pc2gs_corr.pearson.argmax()].name.split('_')[0])\n",
    "y_init = float(SEDext.iloc[:,pc2gs_corr.pearson.argmax()].name.split('_')[1])\n",
    "pts = alt.selection(type=\"single\", encodings=['x','y'], init={'x': x_init, 'y': y_init})\n",
    "\n",
    "heatmap = alt.Chart(pc2gs_corr.reset_index()).mark_circle().encode(\n",
    "    x = alt.X('size_low', scale=alt.Scale(type='log')),\n",
    "    y = alt.Y('size_up', scale=alt.Scale(type='log')),\n",
    "    color = alt.condition(alt.datum.pearson == pc2gs_corr.pearson.max(),\n",
    "                          alt.value('orange'),\n",
    "                          alt.Color('pearson', scale=alt.Scale(scheme='redblue', domain=[-1,1]))),\n",
    "    # size = alt.condition(alt.datum.pearson == pc2gs_corr.pearson.max(),\n",
    "    #                       alt.value('10'),\n",
    "    #                       alt.value('5')),\n",
    "    tooltip = ['pearson', 'spearman', 'size_low', 'size_dif', 'size_up']\n",
    ").add_selection(pts\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600\n",
    ").interactive()\n",
    "\n",
    "\n",
    "scatter = alt.Chart(df.reset_index()).mark_point().encode(\n",
    "    x=pc,\n",
    "    y='value',\n",
    "    tooltip='index'\n",
    ")\n",
    "\n",
    "RegLine = scatter.transform_regression(\n",
    "    pc, 'value', method=\"linear\",\n",
    ").mark_line(\n",
    "    color=\"red\"\n",
    ")\n",
    "\n",
    "RegParams = scatter.transform_regression(\n",
    "    pc, 'value', method=\"linear\", params=True\n",
    ").mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(20),  # pixels from top\n",
    "    text='params:N'\n",
    ").transform_calculate(\n",
    "    params='\"R² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[1] * 100)/100 + \"x\" + \" + \" + round(datum.coef[0] * 10)/10'\n",
    ")\n",
    "\n",
    "text0 = scatter.mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(60),  # pixels from top\n",
    "    text=alt.value('Size bin:')\n",
    ")\n",
    "\n",
    "text1 = scatter.mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(20),  # pixels from left\n",
    "    y=alt.value(80),  # pixels from top\n",
    "    text='variable'\n",
    ")\n",
    "\n",
    "scat_plot = alt.layer(\n",
    "    scatter, RegLine, RegParams, text0, text1\n",
    ").transform_filter(pts\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "alt.hconcat(\n",
    "    heatmap,\n",
    "    scat_plot\n",
    ").resolve_legend(\n",
    "    color=\"independent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Altair size range correlation (MP~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MPsedExt = prepare_data.merge_size_ranges(MPext, 'MP', SEDext, 'SED', cart_prod=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brush1 = alt.selection_interval(name=\"brush1\", encodings=['y'])\n",
    "brush2 = alt.selection_interval(name=\"brush2\", encodings=['x'])\n",
    "\n",
    "step = sed_lower_boundaries[1] - sed_lower_boundaries[0]\n",
    "\n",
    "scatter = alt.Chart(MPsedExt\n",
    ").transform_calculate(\n",
    "    b1l=f'floor((isDefined(brush1.y) ? (brush1.y[0][0]) : 1) / {step}) * {step}',\n",
    "    b1u=f'ceil((isDefined(brush1.y) ? (brush1.y[0][1]) : 1) / {step}) * {step}',\n",
    "    b2l=f'floor((isDefined(brush2.x) ? (brush2.x[0][0]) : 1) / {step}) * {step}',\n",
    "    b2u=f'ceil((isDefined(brush2.x) ? (brush2.x[0][1]) : 1) / {step}) * {step}',\n",
    ").mark_point().encode(\n",
    "    x = 'SED',\n",
    "    y = 'MP',\n",
    "    tooltip = 'sample:N'\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP >= datum.b1l) &&'\n",
    "    '(datum.upper_MP <= datum.b1u) &&'\n",
    "    '(datum.lower_SED >= datum.b2l) &&'\n",
    "    '(datum.upper_SED <= datum.b2u)'\n",
    ")\n",
    "    \n",
    "\n",
    "RegLine = scatter.transform_regression(\n",
    "    'SED', 'MP', method=\"linear\",\n",
    ").mark_line(\n",
    "    color=\"red\"\n",
    ")\n",
    "\n",
    "\n",
    "RegParams = scatter.transform_regression(\n",
    "    'SED', 'MP', method=\"linear\", params=True\n",
    ").mark_text(align='left', lineBreak='\\n').encode(\n",
    "    x=alt.value(120),  # pixels from left\n",
    "    y=alt.value(20),  # pixels from top\n",
    "    text='params:N'\n",
    ").transform_calculate(\n",
    "    params='\"r² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[1] * 100)/100 + \"x\" + \" + \" + round(datum.coef[0] * 10)/10'\n",
    ")\n",
    "\n",
    "\n",
    "MP = alt.Chart(MPsedExt).mark_line().encode(\n",
    "    x = 'mean(MP)',\n",
    "    y = alt.X('lower_MP', scale=alt.Scale(type='linear'))\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP == datum.lower_SED) && \\\n",
    "     (datum.upper_MP == datum.upper_SED)'\n",
    ").add_selection(\n",
    "    brush1\n",
    ").properties(\n",
    "    height = 300,\n",
    "    width = 100\n",
    ")\n",
    "\n",
    "\n",
    "sed = alt.Chart(MPsedExt).mark_line().encode(\n",
    "    x = alt.X('lower_SED', scale=alt.Scale(type='linear')),\n",
    "    y = 'mean(SED)'\n",
    ").transform_filter(\n",
    "    '(datum.lower_MP == datum.lower_SED) &&'\n",
    "    '(datum.upper_MP == datum.upper_SED)'\n",
    ").add_selection(\n",
    "    brush2\n",
    ").properties(\n",
    "    height = 100,\n",
    "    width = 400\n",
    ")\n",
    "\n",
    "\n",
    "MP | (scatter + RegLine + RegParams) & sed\n",
    "\n",
    "# chart = MP | scatter & sed\n",
    "# chart#.save('chart.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Size range correlation matrix (MP~Sed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a correlation matrix containing Pearson correlation coefficients for all combinations of any original or summed bins of MP and sediments.\n",
    "corrMat = np.corrcoef(MPext,SEDext)\n",
    "corrMat = corrMat[:len(MPext), len(SEDext):]  # only take upper right quadrant of correlation matrix\n",
    "\n",
    "corrMatDF = pd.DataFrame(corrMat, index=MPext.index, columns=SEDext.index)  # turn np array into df\n",
    "# corrMatDF.rename('MP_{}'.format, axis=0, inplace=True)  # add a prefix for 'MP' to each row label\n",
    "# corrMatDF.rename('SED_{}'.format, axis=1, inplace=True)  # add a prefix for 'sediment' to each column label\n",
    "corrMatDF.index.name = 'MP'\n",
    "corrMatDF.columns.name = 'SED'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run a cross-correlation for each sample between MP and sediment size distribution curve shapes.\n",
    "crosscorr_results = pd.DataFrame()\n",
    "\n",
    "for label, content in df_range_conc.items():\n",
    "    datax = content\n",
    "    datay = grainsize_iow[label]\n",
    "    #best = correlations.crosscorr(datax, datay)\n",
    "        \n",
    "#     lags = range(-int(len(datax)/2), int(len(datax)/2)+1)\n",
    "    lags = range(-50,0)\n",
    "    df_r = pd.DataFrame(lags, columns = ['shifted'])\n",
    "    \n",
    "#     r_pear = [datax.corr(datay.shift(lag)) for lag in lags]\n",
    "#     df_r['pearson_r'] = r_pear\n",
    "    r_spear = [stats.spearmanr(np.array(datax),np.array(datay.shift(lag)), nan_policy = 'omit') for lag in lags]\n",
    "    df_r['spearman_r'] = r_spear\n",
    "    \n",
    "    \n",
    "    best = df_r.copy().loc[df_r['spearman_r'] == df_r['spearman_r'].max()]\n",
    "    best['Sample'] = label\n",
    "    crosscorr_results = crosscorr_results.append(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MP-to-Scalar correlation (e.g. TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sdd_iow).mark_point().encode(\n",
    "    alt.X(alt.repeat(\"column\"), type='quantitative'),\n",
    "    y = 'Concentration',\n",
    "    color = 'Regio_Sep',\n",
    "    tooltip = 'Sample'\n",
    ").repeat(\n",
    "    column=['D50', 'TOC', 'Dist_WWTP', 'Mass', 'Split']\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(sdd_iow, x='Dist_WWTP', y='D50', z='Concentration',\n",
    "                    color='TOC', symbol='regio_sep', hover_name=\"Sample\",\n",
    "                    color_continuous_scale=px.colors.sequential.turbid_r)\n",
    "\n",
    "# resize markers\n",
    "fig.update_traces(marker=dict(size=4,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "\n",
    "# change size and move colorbar\n",
    "fig.update_layout(autosize=False, width=1000, height=800,\n",
    "                  coloraxis_colorbar=dict(yanchor=\"top\", y=1, x=0, ticks=\"outside\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate correlation between all size bins (or their summed up combinations) of MP abundances and a scalar predictor.\n",
    "# Possible predictors are: 'TOC', 'Hg', 'Dist_WWTP' or different sediment grain size properties (D50, below 63, etc.). See column labels of sdd_MP_sed for a full list.\n",
    "bestLower, bestUpper, df_r = correlations.predictorcorr(df_range_conc, sdd_iow.set_index('Sample'), 'TOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Heatmap correlation coefficients from the single predictor correlation\n",
    "alt.renderers.enable('html')\n",
    "\n",
    "alt.Chart(df_r).mark_point().encode(\n",
    "    x='lower_size',\n",
    "    y='upper_size',\n",
    "    color=alt.Color(\"r\", scale=alt.Scale(domain=[0.5, 0.6])),\n",
    "    tooltip=['r', 'lower_size', 'upper_size']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% size-ranged TOC correlations\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "#####USED only for testing external function inside NB: #####\n",
    "step = (Config.upper_size_limit - Config.lower_size_limit) / Config.kde_steps\n",
    "df_r = pd.DataFrame(columns=['lower_size', 'upper_size', 'r', 'p'])\n",
    "\n",
    "for i in [10]:\n",
    "    for j in [1000]:\n",
    "        size_sum = size_pdfs.loc[(size_pdfs.x_d >= i) & (size_pdfs.x_d < j)].sum()\n",
    "        size_sum.drop('x_d', inplace=True)\n",
    "        range_prob = size_sum * step\n",
    "        range_conc = range_prob * sdd_iow.set_index('Sample').Concentration\n",
    "\n",
    "        r = stats.pearsonr(range_conc, sdd_iow.set_index('Sample').TOC)\n",
    "        df_r.loc[len(df_r)] = [i, j, r[0], r[1]]\n",
    "        print(f'Correlating TOC with size range            [{i},        {j}]                ', end=\"\\r\", flush=True)\n",
    "\n",
    "print(df_r.loc[df_r.r == df_r.r.max()])\n",
    "bestLower, bestUpper = df_r.loc[df_r.r == df_r.r.max()].iloc[0, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "TOC"
    ]
   },
   "outputs": [],
   "source": [
    "# Property-property-plot with MP against single predictor incl. reg line \n",
    "kd = alt.Chart(pd.DataFrame([range_conc, sdd_iow.set_index('Sample').TOC]).T.reset_index()).mark_point().encode(\n",
    "    x='TOC',\n",
    "    y='Unnamed 0',\n",
    "    color='index',\n",
    "    tooltip='index'\n",
    ")\n",
    "\n",
    "Reg_Line = kd.transform_regression('TOC', 'Unnamed 0', method=\"linear\",\n",
    "                                  ).mark_line(color=\"red\")\n",
    "\n",
    "Reg_Params = kd.transform_regression('TOC', 'Unnamed 0', method=\"linear\", params=True\n",
    "                                    ).mark_text(align='left', lineBreak='\\n').encode(\n",
    "        x=alt.value(120),  # pixels from left\n",
    "        y=alt.value(20),  # pixels from top\n",
    "        text='params:N'\n",
    "    ).transform_calculate(\n",
    "        params='\"r² = \" + round(datum.rSquared * 100)/100 + \\\n",
    "    \"      y = \" + round(datum.coef[0] * 10)/10 + \" + e ^ (\" + round(datum.coef[1] * 10000)/10000 + \"x\" + \")\" + \\n + \" \"'\n",
    "    )\n",
    "\n",
    "kd + Reg_Line + Reg_Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daf = grainsize_iow.reset_index().melt(id_vars='index', value_name='value')\n",
    "daf['size'] = daf['index'].str.split('_').str[0]\n",
    "daf['category'] = 'sediment'\n",
    "\n",
    "daff = df_range_conc.reset_index().melt(id_vars='index', value_name='value')\n",
    "daff['size'] = daf['index'].str.split('_').str[0]\n",
    "daff['category'] = 'MP'\n",
    "\n",
    "df = pd.concat([daf, daff]).drop(columns=['index'])\n",
    "# df = daf.merge(daff, on =['sample', 'size', 'index']).drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dropdown = alt.binding_select(options=list(df['sample'].unique()), name='select sample ')\n",
    "selection = alt.selection_single(fields=['sample'],\n",
    "                                 bind=input_dropdown,\n",
    "                                 #init={'select_': 'Schlei_S8'}\n",
    "                                )\n",
    "\n",
    "base = alt.Chart(df).mark_line().encode(\n",
    "    x=alt.X('size:Q'),\n",
    "    y=alt.Y('value:Q'),\n",
    "    color='category',\n",
    "#     shape='category',\n",
    "#     detail='category'\n",
    "# ).transform_window(\n",
    "#     cuml='sum(value)',\n",
    "#     groupby=['sample']\n",
    ").transform_filter(\n",
    "    alt.FieldRangePredicate(field='size', range=[50, 990])\n",
    "# ).properties(\n",
    "#     width=180,\n",
    "#     height=180\n",
    "# ).facet(\n",
    "#     facet='sample',\n",
    "#     columns=6\n",
    "# ).resolve_scale(\n",
    "#     y='independent'\n",
    ")\n",
    "\n",
    "\n",
    "mps = base.mark_line(color='blue').transform_filter(\n",
    "    alt.FieldEqualPredicate(field='category', equal='MP')\n",
    ")\n",
    "seds = base.mark_line(color='yellow').transform_filter(\n",
    "    alt.FieldEqualPredicate(field='category', equal='sediment')\n",
    ")\n",
    "\n",
    "alt.layer(mps, seds).resolve_scale(\n",
    "    y = 'independent'\n",
    ").add_selection(\n",
    "    selection\n",
    ").transform_filter(\n",
    "    selection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = alt.Chart(df).encode(\n",
    "    alt.X('size:Q', axis=alt.Axis(title=None))\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ")\n",
    "\n",
    "mps = base.mark_line(stroke='#57A44C', interpolate='monotone').encode(\n",
    "    alt.Y('MP:Q', axis=alt.Axis(title='MP', titleColor='#57A44C'))\n",
    ")\n",
    "\n",
    "seds = base.mark_line(stroke='#5276A7', interpolate='monotone').encode(\n",
    "    alt.Y('sediment:Q', axis=alt.Axis(title='sediment', titleColor='#5276A7'))\n",
    ")\n",
    "\n",
    "alt.layer(mps, seds).resolve_scale(\n",
    "    y = 'independent'\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ").facet(\n",
    "    facet='sample',\n",
    "    columns=6\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = daf.shift(100).merge(daff, on =['sample', 'size', 'index']).drop(columns=['index'])\n",
    "alt.Chart(df).mark_point().encode(\n",
    "    x=alt.X('value_x', scale=alt.Scale(type='linear')),\n",
    "    y=alt.X('value_y', scale=alt.Scale(type='linear')),\n",
    "    color=alt.Color('size:Q', scale=alt.Scale(scheme=\"viridis\"))\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=150\n",
    ").facet(\n",
    "    facet='sample',\n",
    "    columns=6\n",
    ").resolve_scale(\n",
    "    y='independent',\n",
    "    x='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'x': range(9),\n",
    "    'y': [1, 2, 3, 4, 5, 4, 3, 2, 1]\n",
    "})\n",
    "\n",
    "brush = alt.selection_interval(name=\"brush\", encodings=['x'])\n",
    "alt.Chart(data).mark_line().add_selection(brush).transform_calculate(\n",
    "    scaled_by_brush_width='datum.y * (isDefined(brush.x) ? (brush.x[1] - brush.x[0]) : 1)'\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    y='scaled_by_brush_width:Q'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPSchleiSediments-EUESJ6vo",
   "language": "python",
   "name": "mpschleisediments-euesj6vo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "82a31816b63c673b7463547b8d8376fc489f1e362f1a21f244a13819d6095661"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
